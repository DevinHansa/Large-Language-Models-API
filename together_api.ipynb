{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml\n",
    "import together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables set successfully.\n"
     ]
    }
   ],
   "source": [
    "#setting the credentials required for OPENAI/TOGETHER\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import together\n",
    "\n",
    "try:\n",
    "    # Load credentials from YAML file\n",
    "    with open(\"credentials.yaml\", 'r') as file:\n",
    "        credentials = yaml.safe_load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: credentials.yaml file not found.\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading credentials.yaml: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Ensure credentials loaded successfully and are in the correct format\n",
    "if not isinstance(credentials, dict):\n",
    "    print(\"Error: credentials.yaml does not contain valid credentials.\")\n",
    "    exit(1)\n",
    "\n",
    "# Extract individual credentials\n",
    "OPENAI_API_KEY = credentials.get('OPENAI_API_KEY')\n",
    "TOGETHER_API_KEY = credentials.get('TOGETHER_API_KEY')\n",
    "\n",
    "# Set environment variables\n",
    "try:\n",
    "    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "    together.api_key = TOGETHER_API_KEY\n",
    "    print(\"Environment variables set successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while setting environment variables: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e831864b84b428b8d322d0', 'name': 'Austism/chronos-hermes-13b', 'display_name': 'Chronos Hermes (13B)', 'display_type': 'chat', 'description': 'This model is a 75/25 merge of Chronos (13B) and Nous Hermes (13B) models resulting in having a great ability to produce evocative storywriting and follow a narrative.', 'license': 'other', 'creator_organization': 'Austism', 'hardware_label': '2x A100 80GB', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\", 'add_generation_prompt': True}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0f658Fa41Aa63e663207210CE292F2bcC1C2EE90': 1}, 'asks_updated': '2024-03-25T12:37:38.254810272Z', 'gpus': {'': 0}, 'qps': 0.13333333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 30.333333333333332, 'throughput_out': 3.8666666666666667, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.057971014492753624, 'qps': 0.13333333333333333, 'throughput_in': 30.333333333333332, 'throughput_out': 3.8666666666666667, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6560b993b56cf1e0970c9b1a', 'name': 'BAAI/bge-base-en-v1.5', 'display_name': 'BAAI-Bge-Base-1p5', 'display_type': 'embedding', 'description': 'bge is short for BAAI general embedding, it maps any text to a low-dimensional dense vector using FlagEmbedding', 'license': 'MIT', 'creator_organization': 'BAAI', 'hardware_label': 'A40', 'pricing_tier': 'Featured', 'num_parameters': 109482240, 'release_date': '2023-11-15T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'pricing': {'hourly': 0, 'input': 2, 'output': 2, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-24T14:56:19.475Z', 'update_at': '2023-12-22T03:26:23.802Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 0, 'num_running': 0, 'asks': {'0x4Aa34b8d92E163D7d7527e17B92Bc83C2F7149a3': 1, '0x8BEE38fD0697C19F06411AaEEea935073005168c': 1, '0x947C7D9118573Ef572bA1DbCC093513AA7768352': 1, '0xe2d9B1fd3EfBA3fEB7cfc84FD5d9c1621dA3dEB9': 1}, 'asks_updated': '2024-03-26T00:40:09.687625527Z', 'gpus': {'': 0}, 'qps': 0.4, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 3.8, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.0078125, 'qps': 0.4, 'throughput_in': 3.8, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6560b938b56cf1e0970c9b19', 'name': 'BAAI/bge-large-en-v1.5', 'display_name': 'BAAI-Bge-Large-1p5', 'display_type': 'embedding', 'description': 'bge is short for BAAI general embedding, it maps any text to a low-dimensional dense vector using FlagEmbedding', 'license': 'MIT', 'creator_organization': 'BAAI', 'hardware_label': 'A40', 'pricing_tier': 'Featured', 'num_parameters': 335141888, 'release_date': '2023-11-15T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'pricing': {'hourly': 0, 'input': 4, 'output': 4, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-24T14:54:48.986Z', 'update_at': '2023-12-22T03:27:18.465Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 0, 'num_running': 0, 'asks': {'0x11Dd70a5f8d95F9Fe5e74f330Ed745256bD9be21': 1, '0x5ED0BA75594E3429628087603D628838bE686ebF': 1, '0xD2a55c4769d98e7Df019A3858FA37036BbbAB5cE': 1, '0xF6122ecAc4D8d96a95E00d6eC8a838f4525D8124': 1}, 'asks_updated': '2024-03-26T00:32:37.008907443Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f78861d683768020b9f005', 'name': 'Gryphe/MythoMax-L2-13b', 'display_name': 'MythoMax-L2 (13B)', 'display_type': 'chat', 'description': 'MythoLogic-L2 and Huginn merge using a highly experimental tensor type merge technique. The main difference with MythoMix is that I allowed more of Huginn to intermingle with the single tensors located at the front and end of a model', 'license': 'other', 'creator_organization': 'Gryphe', 'hardware_label': '1x A40 48GB', 'num_parameters': 13000000000, 'release_date': '2023-08-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'add_generation_prompt': True, 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-05T19:58:25.683Z', 'update_at': '2023-09-05T19:58:25.683Z', 'instances': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 30, 'num_bids': 0, 'num_running': 0, 'asks': {'0x004604AaD14CbceC84D2C88a68288fA95c92024c': 1, '0x01E146E05F2a2cD82b78a6EB8BA3AD6e9d1fC249': 1, '0x037DBdcEDb5C34a4fcB41Ab8AaD56b5815bE02DE': 1, '0x05AC032c95A85427d2F5bc4ac46ED7987C8E3370': 1, '0x05a4E02cc4748e92338DCE88e22D81374fD300C9': 1, '0x17957d0c98323Cec3B42BA4a5C0503C5B7114317': 1, '0x1C28d22406B7acff59f57120DcF98685fed4E6d1': 1, '0x2CC40Ddfaf66a26A30ac85e50E4227fe91Ed42d0': 1, '0x2F84CaD2c29FAf002787cBc27A7749871dB843F5': 1, '0x388353D3fF058B989cB0f6a9299A79FC5431ECBf': 1, '0x43A991F613f535419647c299d2Ec38F2DB95e1EB': 1, '0x5498DFe5b80d1FD88b927Fb26CbfeAc3aC262779': 1, '0x639630914e2a03D6ED8B1813Dc61a49D51a6734d': 1, '0x705CE19b5A6BfA9739Ce9160B1DCcaD9c83D9D7e': 1, '0x7101FDCAa53c7E8fF969F4A5Bab72311A9f1a1cf': 1, '0x7986A72CA1d6dE9bD9b1e0ec349a13c92678193b': 1, '0x80Ec6D391649f097c1af115be95f5e67EDD4C86E': 1, '0x866abAD0f44b6C608DF925b864d73D0b0eCb6FAb': 1, '0x8993bDAC643F3500a20c0DdA18af1f6535840aF6': 1, '0x8ef1AD0c945EDD56CE215c751c4d59BE6e7Ba8E5': 1, '0x95d168EF1EA2D60DD7585b0c0C395aD04378C984': 1, '0x997E24eEc58bD8faaF25331dd9Bcfef9ef94B416': 1, '0x9C10b5fe06098EE4475c055A598b03D8AE228B1B': 1, '0x9D76E8FD91d1Ccf7B19e1AbE10144f2721eA5E8F': 1, '0xA5CEf1fA8Dd68B4A185CD38903B0CDfFA343182a': 1, '0xA5De493e5FC052EB73126c793d73888a72Ba7BeC': 1, '0xD613d94dd0aE5d761eDc0f27c8d01F52439B4036': 1, '0xDdCE17cdd6dd4E4bc56F86517cCc4f71E5F0794D': 1, '0xaf9Db30c926d4e48c1314452Ed7C83b05B4a071b': 1, '0xb6F4896c742DdC850AE9f0070B66F1F4608fe397': 1}, 'asks_updated': '2024-03-26T02:54:02.175311751Z', 'gpus': {'': 0}, 'qps': 70.53333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 61176.86666666667, 'throughput_out': 8815.066666666668, 'error_rate': 0.2, 'retry_rate': 0.06666666666666667, 'stats': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub', 'capacity': 0.3839641434262968, 'qps': 70.53333333333333, 'throughput_in': 61176.86666666667, 'throughput_out': 8815.066666666668, 'error_rate': 0.2, 'retry_rate': 0.06666666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6573540efe9a5c79871809ce', 'name': 'Meta-Llama/Llama-Guard-7b', 'display_name': 'Llama Guard (7B)', 'display_type': 'moderation', 'description': 'Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/meta-llama/LlamaGuard-7b', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template': \"{{ '[INST] Task: Check if there is unsafe content in \\\\'' }}{% if messages[messages.length-1]['role'] == 'user' %}{{ 'User' }}{% else %}{{ 'Agent' }}{% endif %}{{ '\\\\' messages in conversations according our safety policy with the below categories.\\n\\n<BEGIN UNSAFE CONTENT CATEGORIES>\\nO1: Violence and Hate. \\nShould not\\n - Help people plan or engage in violence.\\n - Encourage people to engage in violence.\\n - Express hateful, derogatory, or demeaning sentiments against people based on sensitive personal characteristics like their race, color, religion, national origin, sexual orientation, gender, gender identity, or disability.\\n - Encourage discrimination against people based on those characteristics and should not use slurs or create insults based on those characteristics.\\nCan\\n - Provide information on violence and discrimination.\\n - Discuss the topics of hate and violence, and can discuss historical events involving violence.\\nO2: Sexual Content. \\nShould not\\n - Engage in sexually explicit (i.e., erotic) conversations and should not encourage people to engage in sexual activities.\\nCan\\n - Discuss topics related to sexuality and sexual education.\\n - Provide general information regarding sexual activities.\\n - Provide guidance on topics related to sexual health.\\nO3: Criminal Planning. \\nShould not\\n - Help people plan or engage in criminal activities like theft, kidnapping, or financial crimes, especially when the person indicates that they may act on the information provided to them.\\n - Encourage people to engage in criminal activities or condone criminal behavior.\\nCan\\n - Help people understand how crimes are committed, provided that the response is not so detailed that it could be used to provide a roadmap for future crimes.\\n - Help people understand how systems work that are used to prevent crimes, provided those descriptions do not provide detailed information on how to defeat those systems.\\nO4: Guns and Illegal Weapons. \\nShould not\\n - Assist in the planning or execution of firearm or illegal weapons crimes, especially when the person indicates that they may act on the information provided to them.\\n - Encourage people to engage in firearm or illegal weapons crimes or condone such behavior.\\nCan\\n - Discuss firearms and the arguments for and against firearm ownership.\\nO5: Regulated or Controlled Substances. \\nShould not\\n - Encourage or assist people in the trafficking, consumption, or use of regulated or controlled substances, including but not limited to illegal drugs, tobacco, alcohol, and cannabis.\\n - Assist or encourage people to create such substances when it is illegal to do so.\\nCan\\n - Discuss the use of regulated or controlled substances, and can provide general information on those substances (ex: what their chemical composition is and what their effects are).\\n - Provide information on how those substances are manufactured, provided that the information is not so detailed as to provide step-by-step instructions for their creation.\\nO6: Self-Harm. \\nShould not\\n - Encourage people to harm themselves.\\n - Romanticize or condone self-harm or suicide.\\n - Provide information regarding the methods of suicide or self-harm.\\n - Provide any information or advice, other than information regarding appropriate health resources, to people who express or imply that they wish to harm themselves.\\nCan\\n - Provide general information regarding self-harm and suicide (ex: statistics, the mental health challenges faced by those who take these actions).\\nShould\\n - Provide information regarding appropriate health resources to people who imply or express the desire to harm themselves.\\n<END UNSAFE CONTENT CATEGORIES>\\n\\n<BEGIN CONVERSATION>\\n\\n' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ 'User: ' + message['content'] + '\\n\\n' }}{% else %}{{ 'Agent: ' + message['content'] + '\\n\\n' }}{% endif %}{% endfor %}{{ '<END CONVERSATION>\\n\\nProvide your safety assessment for '}}{% if messages[messages.length-1]['role'] == 'user' %}{{ 'User' }}{% else %}{{ 'Agent' }}{% endif %}{{' in the above conversation:\\n - First line must read \\\\'safe\\\\' or \\\\'unsafe\\\\'.\\n - If unsafe, a second line must include a comma-separated list of violated categories. [/INST]' }}\", 'safety_label': 'safe', 'safe_response': True, 'safety_config': {'max_tokens': 64}, 'safety_categories': {'O1': 'Violence and Hate', 'O2': 'Sexual Content', 'O3': 'Criminal Planning', 'O4': 'Guns and Illegal Weapons', 'O5': 'Regulated or Controlled Substances', 'O6': 'Self-Harm'}}, 'pricing': {'input': 6, 'output': 6, 'hourly': 0}, 'update_at': '2024-01-18T17:03:16.859Z', 'instances': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub'}, {'avzone': 'ap-northeast-1a', 'cluster': 'optimisticotter'}, {'avzone': 'us-central-1a', 'cluster': 'sassyseal'}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x3EDb1D647CcB7ac37744870d4AF2Dc8A13FEcE93': 1, '0x4Af456F8E15A15082e24E434Ad794ad9387C7169': 1, '0x4ceB37C5700106874aA40B8DA6b7349Ab7627643': 1, '0xdE2a07701eB6c152C61391E4EA95eeBaAB754f41': 1}, 'asks_updated': '2024-03-26T04:54:51.529061727Z', 'gpus': {'': 0}, 'qps': 18.866666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 22293.533333333333, 'throughput_out': 41.400000000000006, 'stats': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub', 'capacity': 0.07209944751381218, 'qps': 4.933333333333334, 'throughput_in': 5256.066666666667, 'throughput_out': 11.466666666666667, 'error_rate': 0, 'retry_rate': 0}, {'avzone': 'ap-northeast-1a', 'cluster': 'optimisticotter', 'capacity': 0.06355932203389834, 'qps': 4.333333333333333, 'throughput_in': 4628.666666666667, 'throughput_out': 9.666666666666666, 'error_rate': 0, 'retry_rate': 0}, {'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.11245401996847097, 'qps': 5.066666666666666, 'throughput_in': 6569.866666666667, 'throughput_out': 10.466666666666667, 'error_rate': 0, 'retry_rate': 0}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.11278195488721787, 'qps': 4.533333333333333, 'throughput_in': 5838.933333333333, 'throughput_out': 9.8, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '656f5aac044c74c554a30c4f', 'name': 'Nexusflow/NexusRaven-V2-13B', 'display_name': 'NexusRaven (13B)', 'display_type': 'language', 'description': 'NexusRaven is an open-source and commercially viable function calling LLM that surpasses the state-of-the-art in function calling capabilities.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/Nexusflow/NexusRaven-V2-13B', 'creator_organization': 'Nexusflow', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '13000000000', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-12-05T17:15:24.561Z', 'update_at': '2023-12-05T17:15:24.561Z', 'instances': [{'avzone': 'ap-northeast-1a', 'cluster': 'optimisticotter'}], 'descriptionLink': '', 'depth': {'num_asks': 6, 'num_bids': 0, 'num_running': 0, 'asks': {'0x72f158851B24096F1BE379F16d8F07011a1cfd9b': 1, '0x8cFD16e8519E814e58b74DE0f4d96747b2Ce461c': 1, '0x98fAF53B047856a085fb7f7fcc6e37571e11985F': 1, '0xD458a0b34e8e9Cf15231fe8f294cbdF41d59134F': 1, '0xE55822B5482FeE8B805Ad51F47f973270c8AEDe5': 1, '0xF6D77C69d3b3285f085f6977b9B8dB697a22Ae85': 1}, 'asks_updated': '2024-03-25T21:22:40.759090926Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'ap-northeast-1a', 'cluster': 'optimisticotter', 'capacity': 1, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65664e4d79fe5514beebd5d3', 'name': 'NousResearch/Nous-Capybara-7B-V1p9', 'display_name': 'Nous Capybara v1.9 (7B)', 'display_type': 'chat', 'description': 'first Nous collection of dataset and models made by fine-tuning mostly on data created by Nous in-house', 'license': 'MIT', 'creator_organization': 'NousResearch', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 7241732096, 'release_date': '2023-11-15T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'add_generation_prompt': True, 'stop': ['USER:', 'ASSISTANT:'], 'prompt_format': 'USER:\\n{prompt}\\nASSISTANT:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %} {{ 'USER:\\n' + message['content'] + '\\n' }}{% elif message['role'] == 'system' %}{{ 'SYSTEM:\\n' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT:\\n' + message['content'] + '\\n'  }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:\\n' }}{% endif %}{% endfor %}\"}, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-11-28T20:32:13.026Z', 'update_at': '2023-11-28T20:33:03.163Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x1613C26d79fE5b247a531FD393F088f01dC62615': 1, '0x7b766F5f5047BEDaCdE8cf05Fb670f380F055b23': 1}, 'asks_updated': '2024-03-26T07:05:37.366819032Z', 'gpus': {'': 0}, 'qps': 0.2, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 272.53333333333336, 'throughput_out': 8.466666666666667, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.4888888888888889, 'qps': 0.2, 'throughput_in': 272.53333333333336, 'throughput_out': 8.466666666666667, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65d542a20af4aafc88716626', 'name': 'NousResearch/Nous-Hermes-2-Mistral-7B-DPO', 'display_name': 'Nous Hermes 2 - Mistral DPO (7B)', 'display_type': 'chat', 'description': \"Nous Hermes 2 on Mistral 7B DPO is the new flagship 7B Hermes! This model was DPO'd from Teknium/OpenHermes-2.5-Mistral-7B and has improved across the board on all benchmarks tested - AGIEval, BigBench Reasoning, GPT4All, and TruthfulQA.\", 'license': 'apache-2.0', 'link': 'https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO', 'creator_organization': 'NousResearch', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'stop': ['<|im_end|>'], 'chat_template': \"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2024-02-21T00:24:02.387Z', 'update_at': '2024-02-21T00:24:02.387Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x62af740CdDe88172F77E050a397EaB4471bc8C11': 1}, 'asks_updated': '2024-03-25T15:52:12.971220491Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.047619047619047616, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a4b298fbc8405400423169', 'name': 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO', 'display_name': 'Nous Hermes 2 - Mixtral 8x7B-DPO ', 'display_type': 'chat', 'description': 'Nous Hermes 2 Mixtral 7bx8 DPO is the new flagship Nous Research model trained over the Mixtral 7bx8 MoE LLM. The model was trained on over 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO', 'creator_organization': 'NousResearch', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '56000000000', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'stop': ['<|im_end|>', '<|im_start|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 150, 'output': 150, 'hourly': 0}, 'created_at': '2024-01-15T04:20:40.079Z', 'update_at': '2024-01-15T04:20:40.079Z', 'autopilot_pool': 'cr-a100-80-2x', 'instances': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x378500e4443da929DcD0bc73444262E72868Dbf1': 1}, 'asks_updated': '2024-03-25T09:39:40.729332281Z', 'gpus': {'': 0}, 'qps': 0.4666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1326.2, 'throughput_out': 85.33333333333333, 'stats': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub', 'capacity': 0.10588235294117633, 'qps': 0.4666666666666667, 'throughput_in': 1326.2, 'throughput_out': 85.33333333333333, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a4466efbc8405400423166', 'name': 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT', 'display_name': 'Nous Hermes 2 - Mixtral 8x7B-SFT', 'display_type': 'chat', 'description': 'Nous Hermes 2 Mixtral 7bx8 SFT is the new flagship Nous Research model trained over the Mixtral 7bx8 MoE LLM. The model was trained on over 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT', 'creator_organization': 'NousResearch', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '56000000000', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'stop': ['<|im_end|>', '<|im_start|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 150, 'output': 150, 'hourly': 0}, 'created_at': '2024-01-14T20:39:10.060Z', 'update_at': '2024-01-14T20:39:10.060Z', 'autopilot_pool': 'cr-a100-80-2x', 'instances': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x417F2d5eb7362a6eC7f7C6FE86F5120704778cB3': 1}, 'asks_updated': '2024-03-26T00:47:33.477765903Z', 'gpus': {'': 0}, 'qps': 0.13333333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 161.86666666666667, 'throughput_out': 29.2, 'stats': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub', 'capacity': 0.09523809523809523, 'qps': 0.13333333333333333, 'throughput_in': 161.86666666666667, 'throughput_out': 29.2, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '658c8dad27fb98d2edc447ff', 'name': 'NousResearch/Nous-Hermes-2-Yi-34B', 'display_name': 'Nous Hermes-2 Yi (34B)', 'display_type': 'chat', 'description': 'Nous Hermes 2 - Yi-34B is a state of the art Yi Fine-tune', 'license': 'apache-2', 'creator_organization': 'NousResearch', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 34000000000, 'release_date': '2023-12-27T20:48:45.586Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['<|im_start|>', '<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 200, 'output': 200}, 'created_at': '2023-12-27T20:48:45.586Z', 'update_at': '2023-12-27T20:50:38.632Z', 'instances': [{'avzone': 'ap-northeast-1a', 'cluster': 'optimisticotter'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x3d48091C1D0e1cD663dD0D06a6536785524EEe13': 1}, 'asks_updated': '2024-03-22T23:51:12.536783883Z', 'gpus': {'': 0}, 'qps': 0.26666666666666666, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 564.6, 'throughput_out': 30.066666666666666, 'stats': [{'avzone': 'ap-northeast-1a', 'cluster': 'optimisticotter', 'capacity': 0.04615384615384615, 'qps': 0.26666666666666666, 'throughput_in': 564.6, 'throughput_out': 30.066666666666666, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64cae18d3ede2fa7e2cbcc7d', 'name': 'NousResearch/Nous-Hermes-Llama2-13b', 'display_name': 'Nous Hermes Llama-2 (13B)', 'display_type': 'chat', 'description': 'Nous-Hermes-Llama2-13b is a state-of-the-art language model fine-tuned on over 300,000 instructions.', 'license': 'mit', 'creator_organization': 'NousResearch', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'stop': ['###', '</s>'], 'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\", 'add_generation_prompt': True}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-08-02T23:06:53.926Z', 'update_at': '2023-10-07T00:19:33.779Z', 'instances': [{'avzone': 'us-west-1a', 'cluster': 'curiouscrow'}], 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5C93B825665b066F7FE440C13771F18B8FB4B3dE': 1, '0xabb0bFCbcfC7DaC22dd0A6224e55D3b8b0F93b8b': 1}, 'asks_updated': '2024-03-26T07:57:19.936770823Z', 'gpus': {'': 0}, 'qps': 1.6666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 2091.733333333333, 'throughput_out': 130.53333333333333, 'stats': [{'avzone': 'us-west-1a', 'cluster': 'curiouscrow', 'capacity': 0.33, 'qps': 1.6666666666666667, 'throughput_in': 2091.733333333333, 'throughput_out': 130.53333333333333, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf6', 'name': 'NousResearch/Nous-Hermes-llama-2-7b', 'display_name': 'Nous Hermes LLaMA-2 (7B)', 'display_type': 'chat', 'description': 'Nous-Hermes-Llama2-7b is a state-of-the-art language model fine-tuned on over 300,000 instructions.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b', 'creator_organization': 'NousResearch', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 6738415616, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'stop': ['###', '</s>'], 'add_generation_prompt': True, 'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.403Z', 'update_at': '2023-10-24T17:41:52.365Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xf3AbD7152646995C204D8Bee0699AC58653De524': 1}, 'asks_updated': '2024-03-25T13:14:01.042875743Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.06666666666666667, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf5', 'name': 'Open-Orca/Mistral-7B-OpenOrca', 'display_name': 'OpenOrca Mistral (7B) 8K', 'display_type': 'chat', 'description': 'An OpenOrca dataset fine-tune on top of Mistral 7B by the OpenOrca team.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca', 'creator_organization': 'OpenOrca', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 7241748480, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.403Z', 'update_at': '2023-10-24T00:01:52.541Z', 'instances': [{'avzone': 'us-west-1a', 'cluster': 'curiouscrow'}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 0, 'num_running': 0, 'asks': {'0x2463E4d5bDFFbe5479956766Ce5776A2d42FA97B': 1, '0x874820d287Cd06793436c45BE197A1cCC907eAF5': 1, '0xa245C2d619f9EBA6574F2342dD10cE7A6a3b7D23': 1, '0xa819e9222692A296072b54C6710329E967085552': 1}, 'asks_updated': '2024-03-26T07:59:01.031279854Z', 'gpus': {'': 0}, 'qps': 4.733333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 2485.8, 'throughput_out': 201.93333333333334, 'stats': [{'avzone': 'us-west-1a', 'cluster': 'curiouscrow', 'capacity': 0.3313008130081301, 'qps': 2.466666666666667, 'throughput_in': 1410.9333333333334, 'throughput_out': 98.8, 'error_rate': 0, 'retry_rate': 0}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.323549965059399, 'qps': 2.2666666666666666, 'throughput_in': 1074.8666666666666, 'throughput_out': 103.13333333333334, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5cb', 'name': 'Phind/Phind-CodeLlama-34B-v2', 'display_name': 'Phind Code LLaMA v2 (34B)', 'display_type': 'code', 'description': 'Phind-CodeLlama-34B-v1 trained on additional 1.5B tokens high-quality programming-related data proficient in Python, C/C++, TypeScript, Java, and more.', 'license': 'llama2', 'creator_organization': 'Phind', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 33743970304, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': '### System Prompt\\nYou are an intelligent programming assistant.\\n\\n### User Message\\n{prompt}n\\n### Assistant\\n', 'stop': ['</s>'], 'chat_template': \"{{ '### System Prompt\\nYou are an intelligent programming assistant.\\n\\n' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User Message\\n' + message['content'] + '\\n' }}{% else %}{{ '### Assistant\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant\\n' }}\"}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'instances': [{'avzone': 'us-central-5a', 'cluster': 'testytiger'}], 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xA24D97f7BD0B9EcEE97Bd7c76007EaE0994d335D': 1}, 'asks_updated': '2024-03-25T14:07:24.994344239Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-5a', 'cluster': 'testytiger', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c81b4975e79f24d98b50', 'name': 'Qwen/Qwen1.5-0.5B-Chat', 'display_name': 'Qwen 1.5 Chat (0.5B)', 'display_type': 'chat', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 500000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'stop': ['<|im_end|>', '<|im_start|>'], 'chat_template': \"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'add_generation_prompt': True}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2024-02-05T11:35:55.571Z', 'update_at': '2024-02-05T11:35:55.571Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x69d786B0E491C02c3053287F7FD4aa684A0f86B9': 1}, 'asks_updated': '2024-03-26T07:47:42.663406295Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.07142857142857142, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c8164975e79f24d98b4f', 'name': 'Qwen/Qwen1.5-0.5B', 'display_name': 'Qwen 1.5 (0.5B)', 'display_type': 'language', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 500000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2024-02-05T11:35:50.032Z', 'update_at': '2024-02-05T11:35:50.032Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xa01d67F2450E0e7ACBfb7dc8B1a0A3205C5C8310': 1}, 'asks_updated': '2024-03-25T13:01:01.260215885Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.07142857142857142, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c8284975e79f24d98b52', 'name': 'Qwen/Qwen1.5-1.8B-Chat', 'display_name': 'Qwen 1.5 Chat (1.8B)', 'display_type': 'chat', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 1800000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'stop': ['<|im_end|>', '<|im_start|>'], 'chat_template': \"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'add_generation_prompt': True}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2024-02-05T11:36:08.609Z', 'update_at': '2024-02-05T11:36:08.609Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x666Bd30bAD3Ce832d6382156ad94a3913855b4E8': 1}, 'asks_updated': '2024-03-25T17:43:23.464309738Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.16666666666666666, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c8214975e79f24d98b51', 'name': 'Qwen/Qwen1.5-1.8B', 'display_name': 'Qwen 1.5 (1.8B)', 'display_type': 'language', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-1.8B', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 1800000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2024-02-05T11:36:01.895Z', 'update_at': '2024-02-05T11:36:01.895Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xE1E3e79fC7e677c1Bdb8E6f6B6dde0B5d78C2ABc': 1}, 'asks_updated': '2024-03-25T12:30:39.255051114Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.16666666666666666, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c84d4975e79f24d98b58', 'name': 'Qwen/Qwen1.5-14B-Chat', 'display_name': 'Qwen 1.5 Chat (14B)', 'display_type': 'chat', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-14B-Chat', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 14000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'stop': ['<|im_end|>', '<|im_start|>'], 'chat_template': \"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'add_generation_prompt': True}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2024-02-05T11:36:45.529Z', 'update_at': '2024-02-05T11:36:45.529Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xD96D60741d6377B93D3bE70B8bDc7dBA62924292': 1, '0xd460cE633EBa7820EEa3471C2c979088B5B1Ef44': 1}, 'asks_updated': '2024-03-26T06:03:58.224264799Z', 'gpus': {'': 0}, 'qps': 0.06666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 17.733333333333334, 'throughput_out': 3.4, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.38, 'qps': 0.06666666666666667, 'throughput_in': 17.733333333333334, 'throughput_out': 3.4, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c8474975e79f24d98b57', 'name': 'Qwen/Qwen1.5-14B', 'display_name': 'Qwen 1.5 (14B)', 'display_type': 'language', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-14B', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 14000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2024-02-05T11:36:39.431Z', 'update_at': '2024-02-05T11:36:39.431Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x9e16247b23CD03906F4a3e00aFDB4E9817D36182': 1}, 'asks_updated': '2024-03-25T16:16:06.698635025Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.2, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c8344975e79f24d98b54', 'name': 'Qwen/Qwen1.5-4B-Chat', 'display_name': 'Qwen 1.5 Chat (4B)', 'display_type': 'chat', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-4B-Chat', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 4000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'stop': ['<|im_end|>', '<|im_start|>'], 'chat_template': \"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'add_generation_prompt': True}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2024-02-05T11:36:20.314Z', 'update_at': '2024-02-05T11:36:20.314Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xf3A11b6ED83186A97071F40a2da52a10058e55F8': 1}, 'asks_updated': '2024-03-25T18:20:50.039964076Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.16666666666666666, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c82e4975e79f24d98b53', 'name': 'Qwen/Qwen1.5-4B', 'display_name': 'Qwen 1.5 (4B)', 'display_type': 'language', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-4B', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 4000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2024-02-05T11:36:14.800Z', 'update_at': '2024-02-05T11:36:14.800Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xA35444E5703269F80006F8D524f51DEdb2365dA7': 1}, 'asks_updated': '2024-03-25T14:19:02.590202984Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.16666666666666666, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c85a4975e79f24d98b5a', 'name': 'Qwen/Qwen1.5-72B-Chat', 'display_name': 'Qwen 1.5 Chat (72B)', 'display_type': 'chat', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-72B-Chat', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 72000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'stop': ['<|im_end|>', '<|im_start|>'], 'chat_template': \"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'add_generation_prompt': True}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2024-02-05T11:36:58.193Z', 'update_at': '2024-02-05T11:36:58.193Z', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}, {'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 7, 'num_bids': 0, 'num_running': 0, 'asks': {'0x008c841C960950eAB52039F69E0c5e2C84075519': 1, '0x2d21Dd3730a6af13DD344D98f068332b25c75BA0': 1, '0x51F84CE114be459212f9830b4F2180a44439e80D': 1, '0x9e742F0A8420c45f59E3Aead31bE8E613112C322': 1, '0xE8780AdE4869B40b08e7d259423D4BbFCe864C5f': 1, '0xafd57a949AC51c378275980A4dC4346EB5afEb1e': 1, '0xf4b2023581E9c8512496A4336C7df25d95D1C534': 1, '0xfD885493ac18f8ED7D92EE258be5b1c88CE49769': 1}, 'asks_updated': '2024-03-25T23:17:37.99277111Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'error_rate': 0.13333333333333333, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0.5, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0.06666666666666667, 'retry_rate': 0}, {'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.5, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0.06666666666666667, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c8544975e79f24d98b59', 'name': 'Qwen/Qwen1.5-72B', 'display_name': 'Qwen 1.5 (72B)', 'display_type': 'language', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-72B', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 72000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2024-02-05T11:36:52.008Z', 'update_at': '2024-02-05T11:36:52.008Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x37A5f0f9744F5bC79Da7908E1b70C10502C4b4cf': 1, '0xDd729d119c409EbA6E7d42264A74e99BE26301D3': 1}, 'asks_updated': '2024-03-25T13:36:05.544806697Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.3333333333333333, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c8404975e79f24d98b56', 'name': 'Qwen/Qwen1.5-7B-Chat', 'display_name': 'Qwen 1.5 Chat (7B)', 'display_type': 'chat', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-7B-Chat', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'stop': ['<|im_end|>', '<|im_start|>'], 'chat_template': \"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content']}}{% if (loop.last and add_generation_prompt) or not loop.last %}{{ '<|im_end|>' + '\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]['role'] != 'assistant' %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2024-02-05T11:36:32.804Z', 'update_at': '2024-02-05T11:36:32.804Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x150c32dfda47938ec1273Fa267aF64E0A941EFa3': 1}, 'asks_updated': '2024-03-25T14:30:01.568122964Z', 'gpus': {'': 0}, 'qps': 0.3333333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 88, 'throughput_out': 132.6, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.1958333333333333, 'qps': 0.3333333333333333, 'throughput_in': 88, 'throughput_out': 132.6, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c0c83a4975e79f24d98b55', 'name': 'Qwen/Qwen1.5-7B', 'display_name': 'Qwen 1.5 (7B)', 'display_type': 'language', 'description': 'Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model pretrained on a large amount of data. In comparison with the previous released Qwen.', 'license': 'tongyi-qianwen-research', 'link': 'https://huggingface.co/Qwen/Qwen1.5-7B', 'creator_organization': 'Qwen', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2024-02-05T11:36:26.420Z', 'update_at': '2024-02-05T11:36:26.420Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x2ccdcdEf417d5d6D2EeD95dF48f1fcc8Ec1085b2': 1}, 'asks_updated': '2024-03-25T12:58:31.973067353Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.1, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acee11227f790586239d36', 'name': 'SG161222/Realistic_Vision_V3.0_VAE', 'display_name': 'Realistic Vision 3.0', 'display_type': 'image', 'description': 'Fine-tune version of Stable Diffusion focused on photorealism.', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/SG161222/Realistic_Vision_V1.4', 'creator_organization': 'SG161222', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 1024, 'width': 1024, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'created_at': '2023-07-11T05:52:17.219Z', 'update_at': '2023-07-11T05:52:17.219Z', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x1E128f472069E38aEF6B8f25147B42EF81f0F3C0': 1}, 'asks_updated': '2024-03-25T15:27:24.681945234Z', 'gpus': {'NVIDIA A40': 1}, 'options': {'input=text,image': 1}, 'qps': 0.016691703, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.2541989}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655d15e7b56cf1e0970c9b17', 'name': 'Undi95/ReMM-SLERP-L2-13B', 'display_name': 'ReMM SLERP L2 (13B)', 'display_type': 'chat', 'description': 'Re:MythoMax (ReMM) is a recreation trial of the original MythoMax-L2-B13 with updated models. This merge use SLERP [TESTING] to merge ReML and Huginn v1.2.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/Undi95/ReMM-SLERP-L2-13B', 'creator_organization': 'Undi95', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'prompt_format': '[INST]\\n {prompt} \\n[/INST]\\n\\n', 'stop': ['[INST]', '\\n\\n'], 'chat_template_name': 'llama', 'add_generation_prompt': True}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-11-21T20:41:11.759Z', 'update_at': '2023-11-21T20:41:11.759Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x07c96Eeb1Bb52ae6FB40543f6188912775F35d52': 1}, 'asks_updated': '2024-03-26T07:47:46.971926147Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.1, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655d0fecb56cf1e0970c9b16', 'name': 'Undi95/Toppy-M-7B', 'display_name': 'Toppy M (7B)', 'display_type': 'chat', 'description': 'A merge of models built by Undi95 with the new task_arithmetic merge method from mergekit.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/Undi95/Toppy-M-7B', 'creator_organization': 'Undi95', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 7241748480, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['###'], 'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\", 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-11-21T20:15:40.468Z', 'update_at': '2023-11-21T20:15:40.468Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x2fc2e9B51CC4840069a12cFbce35d50D7893d9C6': 1}, 'asks_updated': '2024-03-26T03:56:01.353041742Z', 'gpus': {'': 0}, 'qps': 0.7333333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1444.4666666666667, 'throughput_out': 128.46666666666667, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.09062980030721965, 'qps': 0.7333333333333333, 'throughput_in': 1444.4666666666667, 'throughput_out': 128.46666666666667, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '658504fde7e2e898e81b5400', 'name': 'WhereIsAI/UAE-Large-V1', 'display_name': 'UAE-Large-V1', 'display_type': 'embedding', 'description': 'A universal English sentence embedding WhereIsAI/UAE-Large-V1 achieves SOTA on the MTEB Leaderboard with an average score of 64.64!', 'license': 'apache-2.0', 'link': 'https://huggingface.co/bert-base-uncased', 'creator_organization': 'WhereIsAI', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 330000000, 'show_in_playground': True, 'isFeaturedModel': True, 'pricing': {'hourly': 0, 'input': 4, 'output': 4, 'finetune': 0, 'base': 0}, 'created_at': '2023-12-22T03:39:41.105Z', 'update_at': '2023-12-22T03:45:34.219Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 5, 'num_bids': 0, 'num_running': 0, 'asks': {'0x417487627B27C6F76793D44AEC1C805937e2bCbd': 1, '0x8d48dc97f727317af9dA7c9c384B5E6687C0B9e2': 1, '0x97E9EAE94B8498A57f4F9033A32d722323C294C8': 1, '0xb8Bfb7F25770CfF8bf88ddF1D29237f1D5604d96': 1, '0xeC00Db140f2A64D1682Ca6C47F6EA6B087B50CAc': 1}, 'asks_updated': '2024-03-26T00:34:35.865864322Z', 'gpus': {'': 0}, 'qps': 11.866666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 2314.6666666666665, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.009621888528138528, 'qps': 11.866666666666667, 'throughput_in': 2314.6666666666665, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5cd', 'name': 'WizardLM/WizardCoder-15B-V1.0', 'display_name': 'WizardCoder v1.0 (15B)', 'display_type': 'code', 'description': 'This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.', 'license': 'llama2', 'creator_organization': 'WizardLM', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 15517462528, 'show_in_playground': True, 'context_length': 8192, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:\\n', 'stop': ['###', '<|endoftext|>'], 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x89264c8be6434B3e88115d98dA927644a7EfFD9A': 1}, 'asks_updated': '2024-03-25T13:11:43.806019239Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f672e8bc372ce719b97f02', 'name': 'WizardLM/WizardCoder-Python-34B-V1.0', 'display_name': 'WizardCoder Python v1.0 (34B)', 'display_type': 'code', 'description': 'This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.', 'license': 'llama2', 'creator_organization': 'WizardLM', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'supported', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>', '###'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-09-05T00:14:32.365Z', 'update_at': '2023-09-05T00:14:32.365Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x7ef1A544AE303bc59201A9F1CC5eD2cB24Afb731': 1}, 'asks_updated': '2024-03-26T06:59:43.151880428Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6567d4e5d1c5e59967640530', 'name': 'WizardLM/WizardLM-13B-V1.2', 'display_name': 'WizardLM v1.2 (13B)', 'display_type': 'chat', 'description': 'This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities', 'license': 'llama2', 'creator_organization': 'WizardLM', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 13000000000, 'release_date': '2023-11-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>', 'USER:', 'ASSISTANT:'], 'prompt_format': 'USER: {prompt} ASSISTANT:', 'add_generation_prompt': True, 'chat_template_name': 'llama', 'pre_prompt': \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. \"}, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-11-30T00:18:45.791Z', 'update_at': '2023-11-30T01:20:01.779Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xF9d994b8D62c40bA7532917955dc49D4712C6Ec0': 1}, 'asks_updated': '2024-03-26T07:47:39.624858858Z', 'gpus': {'': 0}, 'qps': 0.2, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 244.06666666666666, 'throughput_out': 50.06666666666667, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.11688311688311691, 'qps': 0.2, 'throughput_in': 244.06666666666666, 'throughput_out': 50.06666666666667, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65df9fa4d28dc68bcefec054', 'name': 'allenai/OLMo-7B-Instruct', 'display_name': 'OLMo Instruct (7B)', 'display_type': 'chat', 'description': 'The OLMo models are trained on the Dolma dataset', 'license': 'apache-2.0', 'link': 'https://huggingface.co/allenai/OLMo-7B-Instruct', 'creator_organization': 'AllenAI', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'eos_token': '<|endoftext|>', 'prompt_format': '<|user|>\\n{prompt}\\n<|assistant|>', 'stop': ['<|endoftext|>'], 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|user|>\\n' + message['content'] + eos_token }}{% elif message['role'] == 'system' %}{{ '<|system|>\\n' + message['content'] + eos_token }}{% elif message['role'] == 'assistant' %}{{ '<|assistant|>\\n'  + message['content'] + eos_token }}{% endif %}{% if loop.last and add_generation_prompt %}{{ '<|assistant|>\\n' }}{% endif %}{% endfor %}\", 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2024-02-28T21:03:32.038Z', 'update_at': '2024-02-28T21:03:32.038Z', 'instances': [{'avzone': 'us-central-2a', 'cluster': 'jollyllama'}], 'isPrivate': False, 'access_control': [], 'isDedicatedInstance': False, 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x9091f727633FB8d8f7Ce1627F5090a62c572610B': 1}, 'asks_updated': '2024-03-26T00:33:12.337362456Z', 'gpus': {'': 0}, 'qps': 0.06666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 27.066666666666666, 'throughput_out': 20.4, 'stats': [{'avzone': 'us-central-2a', 'cluster': 'jollyllama', 'capacity': 0.08333333333333333, 'qps': 0.06666666666666667, 'throughput_in': 27.066666666666666, 'throughput_out': 20.4, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65dfa682d28dc68bcefec055', 'name': 'allenai/OLMo-7B-Twin-2T', 'display_name': 'OLMo Twin-2T (7B)', 'display_type': 'language', 'description': 'The OLMo models are trained on the Dolma dataset', 'license': 'apache-2.0', 'link': 'https://huggingface.co/allenai/OLMo-7B-Twin-2T', 'creator_organization': 'AllenAI', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2024-02-28T21:32:50.812Z', 'update_at': '2024-02-28T21:32:50.812Z', 'instances': [{'avzone': 'us-central-2a', 'cluster': 'jollyllama'}], 'isPrivate': False, 'access_control': [], 'isDedicatedInstance': False, 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xC3c865Bf64f4E3BBa94F2E9b55261833145BD615': 1}, 'asks_updated': '2024-03-26T02:17:46.189965556Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-2a', 'cluster': 'jollyllama', 'capacity': 0.0625, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65dfa6ebd28dc68bcefec056', 'name': 'allenai/OLMo-7B', 'display_name': 'OLMo (7B)', 'display_type': 'language', 'description': 'The OLMo models are trained on the Dolma dataset', 'license': 'apache-2.0', 'link': 'https://huggingface.co/allenai/OLMo-7B', 'creator_organization': 'AllenAI', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2024-02-28T21:34:35.444Z', 'update_at': '2024-02-28T21:34:35.444Z', 'instances': [{'avzone': 'us-central-2a', 'cluster': 'jollyllama'}], 'isPrivate': False, 'access_control': [], 'isDedicatedInstance': False, 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xfDbf46d307E8d3Df8BCDdb2aAAb66340D3D1BA1b': 1}, 'asks_updated': '2024-03-26T00:40:39.959057913Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-2a', 'cluster': 'jollyllama', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6598bc0201bf780326e7eac8', 'name': 'bert-base-uncased', 'display_name': 'Bert Base Uncased', 'display_type': 'embedding', 'description': 'original BERT model', 'license': 'Apache-2', 'creator_organization': 'Google', 'hardware_label': 'A40', 'pricing_tier': 'Featured', 'num_parameters': 46550608, 'release_date': '2023-11-15T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'pricing': {'hourly': 0, 'input': 2, 'output': 2, 'finetune': 0, 'base': 0}, 'created_at': '2024-01-06T02:33:38.323Z', 'update_at': '2024-01-06T02:33:38.323Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 6, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0b7eae8cCeb3D67b02A97ac2D1100E29E6991EB9': 1, '0x21558AA2fCc15eF003135a4108a0884d4A3054f2': 1, '0x2fb2cf26D55c96dc0BAad5f088b0e5Bf0FDe565B': 1, '0x4e0CB8412319d0A4cdEf4C6e14E577c841Ff5c13': 1, '0x5857eaB3609A074E402972C3DDDE8957ea4E7dC5': 1, '0xC412E22A5B1CE26b65B80f2217b9419369057714': 1}, 'asks_updated': '2024-03-26T01:21:28.029025143Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6de95e620478cfa14425b', 'name': 'codellama/CodeLlama-13b-Instruct-hf', 'display_name': 'Code Llama Instruct (13B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'add_generation_prompt': True, 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama'}, 'pricing': {'input': 55, 'output': 55, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-12-04T05:01:42.539Z', 'instances': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 6, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0D4E981904063B0b0DA216Ae282D4db5De2122DB': 1, '0x22A7C18E7ddCeAC8211C24a1AE863D808aab6591': 1, '0x24c7aAdeF14cBc6Bf09F765fD1Ad3643fc4B94BB': 1, '0x5ff72204598E0E10Cf13fB84Cc8B3ce10D1a9a65': 1, '0xED31A9232A6E151721f09ab43d0326267a15816a': 1, '0xdEC856D62F9a5ee0e1dd73e544Ac4e17b7756D09': 1}, 'asks_updated': '2024-03-26T07:53:32.804631086Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6de95e620478cfa14425a', 'name': 'codellama/CodeLlama-13b-Python-hf', 'display_name': 'Code Llama Python (13B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 55, 'output': 55, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-12-20T22:52:59.177Z', 'instances': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x2a58D9f6F093Ef26191d445796cE048E3d09d76c': 1}, 'asks_updated': '2024-03-26T07:41:51.280903155Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6de95e620478cfa144261', 'name': 'codellama/CodeLlama-34b-Instruct-hf', 'display_name': 'Code Llama Instruct (34B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'add_generation_prompt': True, 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama', 'tools_template': \"{{ '<<SYS>>\\\\n' + systemMessage['content'] + '\\\\n\\\\nYou can access the following functions. Use them if required -\\\\n' + tools + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] }}\"}, 'pricing': {'input': 194, 'output': 194, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5AF70F697264302ab412Bd1c3A24FE52cED7e846': 1}, 'asks_updated': '2024-03-25T13:19:37.282571032Z', 'gpus': {'': 0}, 'qps': 0.13333333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 243.53333333333333, 'throughput_out': 49.333333333333336, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0.1394736842105263, 'qps': 0.13333333333333333, 'throughput_in': 243.53333333333333, 'throughput_out': 49.333333333333336, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6de95e620478cfa144260', 'name': 'codellama/CodeLlama-34b-Python-hf', 'display_name': 'Code Llama Python (34B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 194, 'output': 194, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x66edF0D287b56Bdd02daB3F86C6BE0EBC6C4eCd5': 1}, 'asks_updated': '2024-03-25T16:38:07.259505271Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65b6f505752a299002ee4dc9', 'name': 'codellama/CodeLlama-70b-Instruct-hf', 'display_name': 'Code Llama Instruct (70B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/codellama/CodeLlama-70b-Instruct-hf', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '70000000000', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template': \"{{ bos_token + ' ' }}{% for message in messages %}{{'Source: ' + message['role'].trim() }}{% if not message['destination'] is 'undefined' %}{{ '\\n' + 'Destination: ' + message['destination'].trim()  }}{% elif message['role'] == 'system' %}{{ '\\n' + 'Destination: assistant' }}{% elif message['role'] == 'user' %}{{ '\\n' + 'Destination: assistant' }}{% elif message['role'] == 'assistant' %}{{ '\\n' + 'Destination: user'  }}{% endif %}{{ '\\n\\n ' + message['content'].trim() + '<step>'  + ' '}}{% endfor %}{% if add_generation_prompt %}{{ 'Source: assistant' + '\\n' }}{{ 'Destination: user' + '\\n\\n' + ' '  }}{% endif %}\", 'bos_token': '<s>', 'step_id': '<step>', 'stop': ['<step>'], 'add_generation_prompt': True}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2024-01-29T00:44:53.513Z', 'update_at': '2024-01-29T00:44:53.513Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x19Bc9d717837c66C10F51E51F771E9B39F05b1f8': 1}, 'asks_updated': '2024-03-25T14:21:05.270503368Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.010869565217391304, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65b6f4ba752a299002ee4dc7', 'name': 'codellama/CodeLlama-70b-Python-hf', 'display_name': 'Code Llama Python (70B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/codellama/CodeLlama-70b-Python-hf', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '70000000000', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>']}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2024-01-29T00:43:38.396Z', 'update_at': '2024-01-29T00:43:38.396Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xf2a7de1a0E1dC83DC5B1f1dE8783dFEc67be8910': 1}, 'asks_updated': '2024-03-25T15:46:41.935785935Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65b6f4d4752a299002ee4dc8', 'name': 'codellama/CodeLlama-70b-hf', 'display_name': 'Code Llama (70B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/codellama/CodeLlama-70b-hf', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '70000000000', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'stop': ['</s>']}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2024-01-29T00:44:04.149Z', 'update_at': '2024-01-29T00:44:04.149Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xb7cf5cfDa54F6eE9edEcaDE7f4f3d5Ad384f74d4': 1}, 'asks_updated': '2024-03-25T13:18:54.828502398Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6de95e620478cfa14425e', 'name': 'codellama/CodeLlama-7b-Instruct-hf', 'display_name': 'Code Llama Instruct (7B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xeeb92dfc428671623286548d31fc7A7b91198d89': 1}, 'asks_updated': '2024-03-25T17:24:01.080701874Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.3, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6de95e620478cfa14425d', 'name': 'codellama/CodeLlama-7b-Python-hf', 'display_name': 'Code Llama Python (7B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x223046e501B0F456253063d545936D9fF07E42c9': 1, '0x7f8E1Ae54a77a53F9c3c0a5648D1e925bB4E368B': 1}, 'asks_updated': '2024-03-26T07:47:44.660853115Z', 'gpus': {'': 0}, 'qps': 3.3333333333333335, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1266.9333333333334, 'throughput_out': 148.6, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.4491525423728814, 'qps': 3.3333333333333335, 'throughput_in': 1266.9333333333334, 'throughput_out': 148.6, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65c3137e4975e79f24d98b5c', 'name': 'deepseek-ai/deepseek-coder-33b-instruct', 'display_name': 'Deepseek Coder Instruct (33B)', 'display_type': 'chat', 'description': 'Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.', 'license': 'deepseek', 'link': 'https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct', 'creator_organization': 'DeepSeek', 'pricing_tier': 'Featured', 'num_parameters': 33000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': '', 'stop': ['<|EOT|>', '<beginofsentence>', '<endofsentence>'], 'bos_token': '<beginofsentence>', 'add_generation_prompt': True, 'chat_template': \"{{'<beginofsentence>'}}{%- for message in messages %}{%- if message['role'] == 'system' %}{{ message['content'] }}{%- else %}{%- if message['role'] == 'user' %}{{'### Instruction:\\\\n' + message['content'] + '\\\\n'}}{%- else %}{{'### Response:\\\\n' + message['content'] + '\\\\n<|EOT|>\\\\n'}}{%- endif %}{%- endif %}{%- endfor %}{% if add_generation_prompt %}{{'### Response:'}}{% endif %}\"}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2024-02-07T05:22:06.809Z', 'update_at': '2024-02-07T05:22:06.809Z', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x704903F8F953Fa7B648e7bE74C8546E0EdC5d5fC': 1}, 'asks_updated': '2024-03-25T17:02:38.156874638Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0.07142857142857141, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f676f7bc372ce719b97f04', 'name': 'garage-bAInd/Platypus2-70B-instruct', 'display_name': 'Platypus2 Instruct (70B)', 'display_type': 'chat', 'description': 'An instruction fine-tuned LLaMA-2 (70B) model by merging Platypus2 (70B) by garage-bAInd and LLaMA-2 Instruct v2 (70B) by upstage.', 'license': 'CC BY-NC-4.0', 'creator_organization': 'garage-bAInd', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'featured', 'num_parameters': 70000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>', '###'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'add_generation_prompt': True, 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %} {{ '### Instruction:\\n' + message['content'] + '\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n' + message['content'] + '\\n'  }}{% endif %}{% if loop.last %}{{ '### Response:\\n' }}{% endif %}{% endfor %}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-09-05T00:31:51.264Z', 'update_at': '2023-09-07T01:46:29.338Z', 'instances': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xBf6bde62a4B40c3410CcA9fD6e8d975732888381': 1}, 'asks_updated': '2024-03-25T13:43:11.362858721Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub', 'capacity': 0.25, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65d7e89e03b97802d3af0512', 'name': 'google/gemma-2b-it', 'display_name': 'Gemma Instruct (2B)', 'display_type': 'chat', 'description': 'Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.', 'license': 'gemma-terms-of-use', 'link': 'https://huggingface.co/google/gemma-2b-it', 'creator_organization': 'Google', 'pricing_tier': 'Featured', 'num_parameters': 2000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<eos>', '<end_of_turn>'], 'chat_template': \"{{ bos_token }}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{% for message in messages %}{{'<start_of_turn>' + role + '\\n' + message['content'] + '<end_of_turn>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>model\\n' }}{% endif %}\", 'bos_token': '<bos>'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2024-02-23T00:36:46.381Z', 'update_at': '2024-02-23T00:36:46.381Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x30320F09CA3FF5780D553FD1894Aa61E7C42f5Dd': 1}, 'asks_updated': '2024-03-25T13:15:38.63478312Z', 'gpus': {'': 0}, 'qps': 0.13333333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 148.13333333333333, 'throughput_out': 10.8, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.0078125, 'qps': 0.13333333333333333, 'throughput_in': 148.13333333333333, 'throughput_out': 10.8, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65d7e93203b97802d3af0513', 'name': 'google/gemma-2b', 'display_name': 'Gemma (2B)', 'display_type': 'language', 'description': 'Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.', 'license': 'gemma-terms-of-use', 'link': 'https://huggingface.co/google/gemma-2b', 'creator_organization': 'Google', 'pricing_tier': 'Featured', 'num_parameters': 2000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2024-02-23T00:39:14.772Z', 'update_at': '2024-02-23T00:39:14.772Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xF51a7C66471Ec49C0899D38Ce9Af811073E13162': 1}, 'asks_updated': '2024-03-25T12:14:57.116577903Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.0078125, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65d7ea3d03b97802d3af0515', 'name': 'google/gemma-7b-it', 'display_name': 'Gemma Instruct (7B)', 'display_type': 'chat', 'description': 'Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.', 'license': 'gemma-terms-of-use', 'link': 'https://huggingface.co/google/gemma-7b-it', 'creator_organization': 'Google', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<eos>', '<end_of_turn>'], 'chat_template': \"{{ bos_token }}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{% for message in messages %}{{'<start_of_turn>' + role + '\\n' + message['content'] + '<end_of_turn>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>model\\n' }}{% endif %}\", 'bos_token': '<bos>'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2024-02-23T00:43:41.936Z', 'update_at': '2024-02-23T00:43:41.936Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xE98ad4b669B4630B7d05e39B3667c03DaA375BB5': 1}, 'asks_updated': '2024-03-26T07:16:04.456255235Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.041666666666666664, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65d7ea3b03b97802d3af0514', 'name': 'google/gemma-7b', 'display_name': 'Gemma (7B)', 'display_type': 'language', 'description': 'Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.', 'license': 'gemma-terms-of-use', 'link': 'https://huggingface.co/google/gemma-7b', 'creator_organization': 'Google', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2024-02-23T00:43:39.642Z', 'update_at': '2024-02-23T00:43:39.642Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'isPrivate': False, 'access_control': [], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x31FC2819d6Ad59F2B055d6Dc144A51D4678Efdb6': 1}, 'asks_updated': '2024-03-25T14:28:46.870330182Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.041666666666666664, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f678e7bc372ce719b97f06', 'name': 'lmsys/vicuna-13b-v1.5', 'display_name': 'Vicuna v1.5 (13B)', 'display_type': 'chat', 'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.', 'license': 'llama2', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\", 'add_generation_prompt': True}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-05T00:40:07.763Z', 'update_at': '2023-09-05T00:40:07.763Z', 'instances': [{'avzone': 'us-west-1a', 'cluster': 'curiouscrow'}], 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xc4230C6292a2f12D50A54C0D6b0E0f753Cfe8941': 1}, 'asks_updated': '2024-03-26T07:54:50.650493624Z', 'gpus': {'': 0}, 'qps': 0.06666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 56.13333333333333, 'throughput_out': 4.6, 'stats': [{'avzone': 'us-west-1a', 'cluster': 'curiouscrow', 'capacity': 0.09090909090909091, 'qps': 0.06666666666666667, 'throughput_in': 56.13333333333333, 'throughput_out': 4.6, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '652da26579174a6bc507647f', 'name': 'lmsys/vicuna-7b-v1.5', 'display_name': 'Vicuna v1.5 (7B)', 'display_type': 'chat', 'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/lmsys/vicuna-7b-v1.5', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 6738415616, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['</s>', 'USER:'], 'add_generation_prompt': True, 'prompt_format': 'USER: {prompt}\\nASSISTANT: Hello!', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-16T20:51:49.194Z', 'update_at': '2023-10-16T20:51:49.194Z', 'instances': [{'avzone': 'us-west-1a', 'cluster': 'curiouscrow'}], 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x7B9FE2eE4d0De5611C6c9b0d2F8368725c0502e3': 1}, 'asks_updated': '2024-03-26T07:49:03.656231752Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-west-1a', 'cluster': 'curiouscrow', 'capacity': 0.05714285714285714, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6dd9de620478cfa144258', 'name': 'meta-llama/Llama-2-13b-chat-hf', 'display_name': 'LLaMA-2 Chat (13B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/meta-llama/Llama-2-13b-chat-hf', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '13015864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'add_generation_prompt': True, 'chat_template_name': 'llama'}, 'pricing': {'input': 55, 'output': 55, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-12-04T05:00:54.436Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x07BF2767761F4B5dB49c4f256Fae60D5Fa2c09F6': 1}, 'asks_updated': '2024-03-25T12:59:22.134965918Z', 'gpus': {'': 0}, 'qps': 0.26666666666666666, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 26.933333333333334, 'throughput_out': 61.4, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.13999999999999999, 'qps': 0.26666666666666666, 'throughput_in': 26.933333333333334, 'throughput_out': 61.4, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6dd03e620478cfa144255', 'name': 'meta-llama/Llama-2-13b-hf', 'display_name': 'LLaMA-2 (13B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/meta-llama/Llama-2-13b-hf', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '13015864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>']}, 'pricing': {'input': 55, 'output': 55, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-12-04T05:07:52.318Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xb6F5C715d90F639497D8D7FC526BDd50C10BF91a': 1}, 'asks_updated': '2024-03-25T13:33:48.476942042Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.1, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6dd95e620478cfa144257', 'name': 'meta-llama/Llama-2-70b-chat-hf', 'display_name': 'LLaMA-2 Chat (70B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/meta-llama/Llama-2-70b-chat-hf', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '68976648192', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'add_generation_prompt': True, 'chat_template_name': 'llama'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'autopilot_pool': 'cr-a100-80-2x', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}, {'avzone': 'us-central-6a', 'cluster': 'mirthfulmonkey'}], 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 0, 'num_running': 0, 'asks': {'0x20D471BcEdfaAb6f455306747442509A376d7f12': 1, '0x37D77F17647b11d3F962A7624fa89248eeb8A125': 1, '0x559F818fae4766037f162Ca0b27b156fA9cEDF04': 1, '0xA529749e24a956C10483ce9DC0926B5E74236FC7': 1, '0xcaA5A18eBaF49CDe358D73cF8A8395eE35284239': 1}, 'asks_updated': '2024-03-25T18:31:01.109962067Z', 'gpus': {'': 0}, 'qps': 0.13333333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 139.73333333333332, 'throughput_out': 77.6, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0.0125, 'qps': 0.13333333333333333, 'throughput_in': 139.73333333333332, 'throughput_out': 77.6, 'error_rate': 0, 'retry_rate': 0}, {'avzone': 'us-central-6a', 'cluster': 'mirthfulmonkey', 'capacity': 0.021551724137931036, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6dd0ee620478cfa144256', 'name': 'meta-llama/Llama-2-70b-hf', 'display_name': 'LLaMA-2 (70B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/meta-llama/Llama-2-70b-hf', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '68976648192', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>']}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'autopilot_pool': 'cr-a100-80-2x', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}], 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x3914E1675cbf0Ab2a0cAC48077f97f8458B82C82': 1}, 'asks_updated': '2024-03-25T18:13:26.887412527Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0.025, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6dda7e620478cfa144259', 'name': 'meta-llama/Llama-2-7b-chat-hf', 'display_name': 'LLaMA-2 Chat (7B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/meta-llama/Llama-2-7b-chat-hf', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'add_generation_prompt': True, 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}, {'avzone': 'us-central-2a', 'cluster': 'jollyllama'}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x05655a9b3C902ceC9a13CfB61bc8f1FAfCdE7Aa8': 1, '0x0c409751A39422fb09dbd0DB2EE0a2E69Bb29f40': 1, '0x131c7b8C8e9eC24574A2183c99Ad92F7c7a1f82E': 1, '0x63B1A514621b84Ced84a2f26b0fc11A2f964DA7E': 1}, 'asks_updated': '2024-03-26T01:01:02.694631814Z', 'gpus': {'': 0}, 'qps': 4.2, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1593.6, 'throughput_out': 219.8, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.08488372093023248, 'qps': 1.2666666666666666, 'throughput_in': 667.7333333333333, 'throughput_out': 77.73333333333333, 'error_rate': 0, 'retry_rate': 0}, {'avzone': 'us-central-2a', 'cluster': 'jollyllama', 'capacity': 0.09451219512195114, 'qps': 1, 'throughput_in': 152.2, 'throughput_out': 28.866666666666667, 'error_rate': 0, 'retry_rate': 0}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.09000000000000005, 'qps': 1.9333333333333333, 'throughput_in': 773.6666666666666, 'throughput_out': 113.2, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6db78e620478cfa144254', 'name': 'meta-llama/Llama-2-7b-hf', 'display_name': 'LLaMA-2 (7B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/meta-llama/Llama-2-7b-hf', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>']}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x8Dab4948855BcB4d3D1eE3dA4FA46A4c1E0E76c9': 1}, 'asks_updated': '2024-03-25T13:30:18.198053795Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.05, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65b40661251b2ff9f146d8ba', 'name': 'microsoft/phi-2', 'display_name': 'Microsoft Phi-2', 'display_type': 'language', 'description': 'Phi-2 is a Transformer with 2.7 billion parameters. It was trained using the same data sources as Phi-1.5, augmented with a new data source that consists of various NLP synthetic texts and filtered websites (for safety and educational value)', 'license': 'mit', 'link': 'https://huggingface.co/microsoft/phi-2', 'creator_organization': 'Microsoft', 'pricing_tier': 'Featured', 'num_parameters': 2700000000, 'release_date': '2024-01-26T19:22:09.533Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2024-01-26T19:22:09.533Z', 'update_at': '2024-01-26T19:23:46.072Z', 'instances': [{'avzone': 'us-central-2a', 'cluster': 'jollyllama'}], 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x783147c96Ef940c47B13738755D015Eb764db9Bb': 1}, 'asks_updated': '2024-03-26T00:39:49.525888025Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-2a', 'cluster': 'jollyllama', 'capacity': 0.03414634146341464, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6514c873829715ded9cd17b1', 'name': 'mistralai/Mistral-7B-Instruct-v0.1', 'display_name': 'Mistral (7B) Instruct', 'display_type': 'chat', 'description': 'instruct fine-tuned version of Mistral-7B-v0.1', 'license': 'Apache-2', 'creator_organization': 'mistralai', 'hardware_label': '2x A100 80GB', 'num_parameters': 7241732096, 'release_date': '2023-09-27T00:00:00.000Z', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'add_generation_prompt': True, 'stop': ['[/INST]', '</s>'], 'prompt_format': '<s>[INST] {prompt} [/INST]', 'chat_template_name': 'llama', 'tools_template': \"{{ '<<SYS>>\\\\n' + systemMessage['content'] + '\\\\n\\\\nYou can access the following functions. Use them if required -\\\\n' + tools + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-09-28T00:27:31.815Z', 'update_at': '2023-10-12T01:13:51.840Z', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}, {'avzone': 'us-central-6a', 'cluster': 'mirthfulmonkey'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x8c06F1EB7D08474D6dFA2e0FD6A58e5f036B688C': 1, '0x9AbeB80e329d053D14a0E54F45d0947258f18eA8': 1}, 'asks_updated': '2024-03-26T05:59:29.415742662Z', 'gpus': {'': 0}, 'qps': 10.333333333333334, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 2466.2666666666664, 'throughput_out': 1747.9333333333334, 'retry_rate': 0.33333333333333337, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0.2850772415989812, 'qps': 5.133333333333334, 'throughput_in': 1261, 'throughput_out': 872.8, 'error_rate': 0, 'retry_rate': 0.2}, {'avzone': 'us-central-6a', 'cluster': 'mirthfulmonkey', 'capacity': 0.2585525184803165, 'qps': 5.2, 'throughput_in': 1205.2666666666667, 'throughput_out': 875.1333333333333, 'error_rate': 0, 'retry_rate': 0.13333333333333333}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65776c7d6923087ddd5a660a', 'name': 'mistralai/Mistral-7B-Instruct-v0.2', 'display_name': 'Mistral (7B) Instruct v0.2', 'display_type': 'chat', 'description': 'The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an improved instruct fine-tuned version of Mistral-7B-Instruct-v0.1.', 'license': 'apache-2.0', 'creator_organization': 'mistralai', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'release_date': '2023-11-01T00:00:00.000Z', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama', 'tools_template': '{{ \\'If you need to invoke any of the following functions:\\n\\' + tools + \\'\\nplease respond in the following JSON format:\\n[\\n\\n  {\\n    \"name\": \"the name of the function to be invoked\",\\n    \"arguments\": {\"key1\": \"value1\", \"key2\": \"value2\", ...}\\n  }\\n]\\nIf any required arguments are missing, please ask for them without JSON function calls.\\nIf the instruction does not necessitate a function call, please provide your response in clear, concise natural language.\\n\\n\\' + message[\\'content\\'] }}', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-12-11T20:09:33.627Z', 'update_at': '2023-12-11T20:09:33.627Z', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}, {'avzone': 'us-central-6a', 'cluster': 'mirthfulmonkey'}], 'access': '', 'hardware_label': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xD7B067F109ac4Fc217349A192aed14768d5608B0': 1, '0xd283d8640D48d10bfB7E57C9A3188E249e47359A': 1}, 'asks_updated': '2024-03-26T02:20:44.044251469Z', 'gpus': {'': 0}, 'qps': 2.533333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 2507.9333333333334, 'throughput_out': 244.2, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0.1497835497835498, 'qps': 1.4666666666666666, 'throughput_in': 1637, 'throughput_out': 150.33333333333334, 'error_rate': 0, 'retry_rate': 0}, {'avzone': 'us-central-6a', 'cluster': 'mirthfulmonkey', 'capacity': 0.20569105691056902, 'qps': 1.0666666666666667, 'throughput_in': 870.9333333333333, 'throughput_out': 93.86666666666666, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6514c6ee829715ded9cd17b0', 'name': 'mistralai/Mistral-7B-v0.1', 'display_name': 'Mistral (7B)', 'display_type': 'language', 'description': '7.3B parameter model that outperforms Llama 2 13B on all benchmarks, approaches CodeLlama 7B performance on code, Uses Grouped-query attention (GQA) for faster inference and Sliding Window Attention (SWA) to handle longer sequences at smaller cost', 'license': 'Apache-2', 'creator_organization': 'mistralai', 'hardware_label': '2x A100 80GB', 'num_parameters': 7241732096, 'release_date': '2023-09-27T00:00:00.000Z', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': '{prompt}', 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-09-28T00:21:02.330Z', 'update_at': '2023-09-28T00:21:02.330Z', 'instances': [{'avzone': 'us-central-2a', 'cluster': 'jollyllama'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xFbeDD45B97dd29D385Ec4cafFbb4C5f286c90aD5': 1}, 'asks_updated': '2024-03-26T00:40:05.204386967Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-2a', 'cluster': 'jollyllama', 'capacity': 0.045454545454545456, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6577af4434e6c1e2bb5283d8', 'name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'display_name': 'Mixtral-8x7B Instruct v0.1', 'display_type': 'chat', 'description': 'The Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1', 'creator_organization': 'mistralai', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '56000000000', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama', 'tools_template': \"{{ '<<SYS>>\\\\n' + systemMessage['content'] + '\\\\n\\\\nYou can access the following functions. Use them if required -\\\\n' + tools + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] }}\", 'add_generation_prompt': True}, 'pricing': {'input': 150, 'output': 150, 'hourly': 0}, 'created_at': '2023-12-12T00:54:28.108Z', 'update_at': '2024-02-08T07:58:24.624Z', 'autopilot_pool': 'cr-a100-80-2x', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}, {'avzone': 'us-central-6a', 'cluster': 'mirthfulmonkey'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 24, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0C2B50036672dEd5B7c38C1aDd01135B9faECAC4': 1, '0x1B5738E774275Ac739D134bd13fF33Af00F1E5aF': 1, '0x20deb2E948f9E5fcD088f5E3c55d3dC60239cBe9': 1, '0x20e8F7b06AF44F1A9d6018555353e63c5D4B820a': 1, '0x2167e04DEda8289FeB7cB48fff6fACd77706eD61': 1, '0x2F1F729A8a095a3A9a8F891033a08b26939A55D6': 1, '0x4F93bdE91eE740d39962b63cBF730A69a2e4A965': 1, '0x5f0Ee75d651D900402F93C95295a172b42EfCaCE': 1, '0x80190DF09A30326F9F61317A0e8573CaE7A9eBD3': 1, '0x8F66c63231A08460482d28c2bAb08C477113B32A': 1, '0x99bf9CE4b5BC28285dCa908d5F7212918Fe1e19E': 1, '0x9e746d9Ce6AcA805774E68B1f5Cc00b30aeF195C': 1, '0xB2109E74a3adA1b93819Cc5819297DB431654946': 1, '0xBf7888f491a71AB8CB37b92fCA7B8ce1375c0837': 1, '0xCd90B764039752004328747c4d71ea937bC44643': 1, '0xD04bddfE779aCac662E0387EE09F71B889843b42': 1, '0xE09a628E89b1d91a445D0F66cA270D92E2BA1a93': 1, '0xE6ef9e8411202371dB5284810f35f952110204da': 1, '0xF7bfc25e777a0c7f0D104544DbE450fAa89c4553': 1, '0xaCfC53755692CB4fe51b08Fc7BB114037672acBc': 1, '0xbD5B0ba7A93634377e607bd090aa20FEEBaEeee8': 1, '0xbb6C18a9a2321eec9d0d14e12D02a874C63780e4': 1, '0xcE176551596cE7Baa1AB0d9196172fE988219dc9': 1, '0xd11B2391ebcBdEAC1b7a2159EBd5d91603555429': 1, '0xe01Ccb9435141DaF8fBBEAfAC9bCe74B9B2eAaE1': 1}, 'asks_updated': '2024-03-26T00:40:53.795372272Z', 'gpus': {'': 0}, 'qps': 4.666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 9650.266666666666, 'throughput_out': 1085.6, 'retry_rate': 0.2, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0.11031894934333936, 'qps': 2.7333333333333334, 'throughput_in': 6820.4, 'throughput_out': 663.2, 'error_rate': 0, 'retry_rate': 0.06666666666666667}, {'avzone': 'us-central-6a', 'cluster': 'mirthfulmonkey', 'capacity': 0.10814479638009028, 'qps': 1.9333333333333333, 'throughput_in': 2829.866666666667, 'throughput_out': 422.4, 'error_rate': 0, 'retry_rate': 0.13333333333333333}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6577bf1034e6c1e2bb5283d9', 'name': 'mistralai/Mixtral-8x7B-v0.1', 'display_name': 'Mixtral-8x7B v0.1', 'display_type': 'language', 'description': 'The Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/mistralai/Mixtral-8x7B-v0.1', 'creator_organization': 'mistralai', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '56000000000', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'pricing': {'input': 150, 'output': 150, 'hourly': 0}, 'created_at': '2023-12-12T02:01:52.674Z', 'update_at': '2024-02-08T07:58:39.848Z', 'autopilot_pool': 'cr-a100-80-2x', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xB42b44a33305F8e04d7C22EE6cfA6D6B89ed2401': 1}, 'asks_updated': '2024-03-25T13:27:02.642894501Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.07692307692307693, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '657b7a2a84ef58c3562de91e', 'name': 'openchat/openchat-3.5-1210', 'display_name': 'OpenChat 3.5', 'display_type': 'chat', 'description': 'A merge of OpenChat 3.5 was trained with C-RLFT on a collection of publicly available high-quality instruction data, with a custom processing pipeline.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/openchat/openchat-3.5-1210', 'creator_organization': 'OpenChat', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '7000000000', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'chat_template': \"{{ bos_token }}{% for message in messages %}{{ 'GPT4 Correct ' + message['role'] + ': ' + message['content'] + '<|end_of_turn|>'}}{% endfor %}{% if add_generation_prompt %}{{ 'GPT4 Correct Assistant:' }}{% endif %}\", 'stop': ['<|end_of_turn|>', '</s>'], 'add_generation_prompt': True, 'bos_token': '<s>', 'prompt_format': 'GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-12-14T21:56:58.576Z', 'update_at': '2023-12-14T21:56:58.576Z', 'instances': [{'avzone': 'ap-northeast-1a', 'cluster': 'optimisticotter'}], 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x7c2e432720fC11Cd177eFf01BD7Fb55B705EFB2E': 1}, 'asks_updated': '2024-03-25T04:55:34.971651832Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'ap-northeast-1a', 'cluster': 'optimisticotter', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aced5c227f790586239d2b', 'name': 'prompthero/openjourney', 'display_name': 'Openjourney v4', 'display_type': 'image', 'description': 'An open source Stable Diffusion model fine tuned model on Midjourney images. ', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/prompthero/openjourney', 'creator_organization': 'Prompt Hero', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 512, 'width': 512, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:49:16.586Z', 'update_at': '2023-07-11T05:49:16.586Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5C5b60Ea2C7046FDdf7F7be3853d046301334a85': 1, '0xB2bFeaa446Cc0376249ed2d7a8f5C32E0705e556': 1}, 'asks_updated': '2024-03-25T22:58:04.782856144Z', 'gpus': {'NVIDIA A40': 2}, 'options': {'input=text,image': 2}, 'qps': 0.014200849, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.25410485}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece1', 'name': 'runwayml/stable-diffusion-v1-5', 'display_name': 'Stable Diffusion 1.5', 'display_type': 'image', 'description': 'Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/runwayml/stable-diffusion-v1-5', 'creator_organization': 'Runway ML', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 512, 'width': 512, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'created_at': '2023-06-23T20:22:43.572Z', 'update_at': '2023-06-23T20:22:43.572Z', 'access': '', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x98D41CFC96e488D9810431B65Aa98EBfc87b73c8': 1}, 'asks_updated': '2024-03-25T13:12:34.039528983Z', 'gpus': {'NVIDIA A40': 1}, 'options': {'input=text,image': 1}, 'qps': 0.020016838, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 4.066161}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65460075c5ce2e5fa70d6721', 'name': 'sentence-transformers/msmarco-bert-base-dot-v5', 'display_name': 'Sentence-BERT', 'display_type': 'embedding', 'description': 'A sentence-transformers model: it maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/sentence-transformers/msmarco-bert-base-dot-v5', 'creator_organization': 'Together', 'hardware_label': 'L40', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 110000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 512, 'pricing': {'hourly': 0, 'input': 2, 'output': 2, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-04T08:27:33.867Z', 'update_at': '2023-12-22T03:15:44.832Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 0, 'num_running': 0, 'asks': {'0x12A5aA174921D1A107E2c4f8a1b7fbf262B548e3': 1, '0x662c7EE2ca9D3D4fAbcEE2286C1bbc5f24CA02fD': 1, '0x834Dfa4EeF072100CcBC96fA3871d6f62Ce02455': 1, '0xfE0CBc639aB99C5995B77cBd6aCCB0F29208186D': 1}, 'asks_updated': '2024-03-26T00:37:42.293819195Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65b454f3d9877b0bd1376470', 'name': 'snorkelai/Snorkel-Mistral-PairRM-DPO', 'display_name': 'Snorkel Mistral PairRM DPO (7B)', 'display_type': 'chat', 'description': 'A state-of-the-art model by Snorkel AI, DPO fine-tuned on Mistral-7B', 'license': 'apache-2.0', 'creator_organization': 'Snorkel AI', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'release_date': '2024-01-27T00:57:23.638Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2024-01-27T00:57:23.638Z', 'update_at': '2024-01-27T14:24:41.745Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'hardware_label': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x905d9333Bf36FC9fD26b130adaaEe6f5Bd4E800f': 1}, 'asks_updated': '2024-03-26T07:47:43.911391589Z', 'gpus': {'': 0}, 'qps': 0.2, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 430.06666666666666, 'throughput_out': 80.2, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.12592592592592594, 'qps': 0.2, 'throughput_in': 430.06666666666666, 'throughput_out': 80.2, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acef00227f790586239d3b', 'name': 'stabilityai/stable-diffusion-2-1', 'display_name': 'Stable Diffusion 2.1', 'display_type': 'image', 'description': 'Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.', 'license': 'openrail++', 'link': 'https://huggingface.co/stabilityai/stable-diffusion-2-1', 'creator_organization': 'Stability AI', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'created_at': '2023-06-23T20:22:43.572Z', 'update_at': '2023-06-23T20:22:43.572Z', 'access': '', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xC9494f3A014EAC6DD43De5b03E03364F1AcC9ea7': 1}, 'asks_updated': '2024-03-25T09:30:25.785544059Z', 'gpus': {'NVIDIA A100 80GB PCIe': 1}, 'options': {'input=text,image': 1}, 'qps': 0.020150112, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 2.189547}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64c9890c689aa3b286cfcff9', 'name': 'stabilityai/stable-diffusion-xl-base-1.0', 'display_name': 'Stable Diffusion XL 1.0', 'display_type': 'image', 'description': 'A text-to-image generative AI model that excels at creating 1024x1024 images.', 'license': 'openrail++', 'link': 'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0', 'creator_organization': 'Stability AI', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'seed': 1000, 'height': 1024, 'width': 1024, 'steps': 40, 'number_of_images': 4}, 'created_at': '2023-08-01T22:37:00.851Z', 'update_at': '2023-08-01T22:37:00.851Z', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x2E595c6ee5e62FeFF9f426b239a2fB0970476593': 1}, 'asks_updated': '2024-03-24T22:33:16.967126023Z', 'gpus': {'NVIDIA A100 80GB PCIe': 1}, 'options': {'input=text,image': 1}, 'qps': 0.053102378, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 3.458351}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '653c053fd9679a84df55c4e7', 'name': 'teknium/OpenHermes-2-Mistral-7B', 'display_name': 'OpenHermes-2-Mistral (7B)', 'display_type': 'chat', 'description': 'State of the art Mistral Fine-tuned on extensive public datasets', 'license': 'Apache-2', 'creator_organization': 'teknium', 'hardware_label': 'A40', 'pricing_tier': 'Featured', 'num_parameters': 7241732096, 'release_date': '2023-10-27T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<|im_end|>', '<|im_start|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'pre_prompt': '<|im_start|>system\\nYou are thoughtful, helpful, polite, honest, and friendly<|im_end|>\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-27T18:45:19.307Z', 'update_at': '2023-10-27T23:53:05.438Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}, {'avzone': 'us-central-5a', 'cluster': 'wrigleycub'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x19604601864CF5e0d5E9F27D6D9Ff753A7f4C6A5': 1, '0x24e7c0F944a664e4be6890a13Ce3cB0b930a2d9b': 1}, 'asks_updated': '2024-03-25T13:29:18.851117413Z', 'gpus': {'': 0}, 'qps': 0.26666666666666666, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 412, 'throughput_out': 53.333333333333336, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.06363636363636364, 'qps': 0.13333333333333333, 'throughput_in': 202.93333333333334, 'throughput_out': 26.666666666666668, 'error_rate': 0, 'retry_rate': 0}, {'avzone': 'us-central-5a', 'cluster': 'wrigleycub', 'capacity': 0.19166666666666668, 'qps': 0.13333333333333333, 'throughput_in': 209.06666666666666, 'throughput_out': 26.666666666666668, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655667fe6664bf7229b2dc6c', 'name': 'teknium/OpenHermes-2p5-Mistral-7B', 'display_name': 'OpenHermes-2.5-Mistral (7B)', 'display_type': 'chat', 'description': 'Continuation of OpenHermes 2 Mistral model trained on additional code datasets', 'license': 'Apache-2', 'creator_organization': 'teknium', 'hardware_label': 'A40', 'pricing_tier': 'Featured', 'num_parameters': 7241732096, 'release_date': '2023-11-15T00:00:00.000Z', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<|im_end|>', '<|im_start|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-11-16T19:05:34.976Z', 'update_at': '2023-11-16T19:12:24.883Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 0, 'num_running': 0, 'asks': {'0x3758229A3733c45E38cEb6a5CDd5Cca100F0F651': 1, '0x984FD1c2c26dE83Cd9D762eFCEaAf240bDc327b0': 1, '0xC24C8C160a7f870d4e0063e434d9A507E59A2e51': 1}, 'asks_updated': '2024-03-26T07:22:13.282170434Z', 'gpus': {'': 0}, 'qps': 2.8, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 4219.8, 'throughput_out': 419.6, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.33676268861454045, 'qps': 2.8, 'throughput_in': 4219.8, 'throughput_out': 419.6, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece3', 'name': 'togethercomputer/GPT-JT-Moderation-6B', 'display_name': 'GPT-JT-Moderation (6B)', 'display_type': 'language', 'description': \"This model can be used to moderate other chatbot models. Built using GPT-JT model fine-tuned on Ontocord.ai's OIG-moderation dataset v0.1.\", 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/GPT-JT-Moderation-6B', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 6700000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template': \"Possible labels:\\n1. casual\\n2. needs caution\\n3. needs intervention\\n4. possibly needs caution\\n5. probably needs caution\\nInput: Hi!\\nOutput: casual\\nInput: I want to kill my cat.\\nOutput: needs intervention\\nInput: How to poison my dog?\\nOutput: needs intervention\\nInput: I don't want to talk to my brother\\nOutput: probably needs caution\\nInput: Today we had a disagreement and  \\nwe got into a screaming fight. I don't want to talk.\\nOutput: probably needs caution\\nInput: My brother is being an asshole... Fuck him.\\nOutput: needs caution\\nInput: Hello.\\nOutput: casual\\nInput: {% for message in messages %}{{ message.content }}{{ eos_token }}{% endfor %}\\nOutput:\", 'safety_label': 'casual', 'safety_config': {'temperature': 0.2, 'top_p': 1, 'max_tokens': 10, 'stop': ['\\n']}}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.657Z', 'update_at': '2023-06-23T20:22:43.657Z', 'instances': [{'avzone': 'us-central-5a', 'cluster': 'testytiger'}], 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x3B2a3D16B0207aA9F14726eeE8cD0b9b388209A2': 1}, 'asks_updated': '2024-03-24T21:56:54.280071422Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-5a', 'cluster': 'testytiger', 'capacity': 0.05, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64c28e8742fa06a9511509d1', 'name': 'togethercomputer/LLaMA-2-7B-32K', 'display_name': 'LLaMA-2-32K (7B)', 'display_type': 'language', 'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations.\", 'license': 'Meta license', 'link': 'https://huggingface.co/togethercomputer/LLaMA-2-7B-32K', 'creator_organization': 'Together', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'stop': ['\\n\\n\\n\\n', '<|endoftext|>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-27T15:34:31.581Z', 'update_at': '2023-08-17T17:07:36.346Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'descriptionLink': '', 'depth': {'num_asks': 6, 'num_bids': 0, 'num_running': 0, 'asks': {'0x39d6b56b1DFc4F45adE83b4873Fc235b3f9a139d': 1, '0x4841AF13c668402bb7900026dD06AFb39665dd04': 1, '0x59873BED79244f07Ea09E4F687CC06865CCC2665': 1, '0xCea71912Fc8c70d37112357fd9a1476E10647c6E': 1, '0xbB0cFb278708b7b3DcE1dA6F64Fe3E5c3862dF6c': 1, '0xeC077518119D8E3b67732FE328f3b3c51763E024': 1}, 'asks_updated': '2024-03-26T07:13:10.366776659Z', 'gpus': {'': 0}, 'qps': 0.2, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 266.6666666666667, 'throughput_out': 318.26666666666665, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 2.5625, 'qps': 0.2, 'throughput_in': 266.6666666666667, 'throughput_out': 318.26666666666665, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64de96090d052d10425df3c9', 'name': 'togethercomputer/Llama-2-7B-32K-Instruct', 'display_name': 'LLaMA-2-7B-32K-Instruct (7B)', 'display_type': 'chat', 'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations, instruction tuned by Together\", 'license': 'Meta license', 'link': 'https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct', 'creator_organization': 'Together', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '[INST]\\n {prompt} \\n[/INST]\\n\\n', 'stop': ['[INST]', '\\n\\n'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-27T15:34:31.581Z', 'update_at': '2023-08-17T17:07:36.346Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'descriptionLink': '', 'depth': {'num_asks': 6, 'num_bids': 0, 'num_running': 0, 'asks': {'0x1Dc444338B3B1d753391331881691f8d0f799A19': 1, '0x5055125302C75cE3927Dcad40D6B595d2bCaA951': 1, '0x7cFca2eb72819e54087d5C35A56A6Fc93223Fd61': 1, '0x8277aaf3aA667bc709FAe3aa913281512444b8d6': 1, '0xA6d5A64D8c618e0c72E585fC8d01Cdd86C1C6fc2': 1, '0xC7C03928E928Ad4b17802EF9dce493fAf79920e3': 1}, 'asks_updated': '2024-03-26T07:56:11.995277522Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 1, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aeceb', 'name': 'togethercomputer/RedPajama-INCITE-7B-Base', 'display_name': 'RedPajama-INCITE (7B)', 'display_type': 'language', 'description': 'Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).', 'descriptionLink': 'https://www.together.xyz/blog/redpajama-models-v1', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '6857302016', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.033Z', 'update_at': '2023-06-23T20:22:44.033Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x481cEDE4Db74BEf182dA2D52e410013D41fb5980': 1}, 'asks_updated': '2024-03-25T12:22:01.911371579Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.0078125, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aeced', 'name': 'togethercomputer/RedPajama-INCITE-7B-Chat', 'display_name': 'RedPajama-INCITE Chat (7B)', 'display_type': 'chat', 'description': 'Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-7B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat', 'creator_organization': 'Together', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '6857302016', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.190Z', 'update_at': '2023-06-23T20:22:44.190Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x25C9f9263DCbB16597cfe1b6bf8293971A277BAC': 1}, 'asks_updated': '2024-03-25T13:46:30.334293555Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.0078125, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecec', 'name': 'togethercomputer/RedPajama-INCITE-7B-Instruct', 'display_name': 'RedPajama-INCITE Instruct (7B)', 'display_type': 'language', 'description': 'Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-7B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct', 'creator_organization': 'Together', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '6857302016', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.083Z', 'update_at': '2023-06-23T20:22:44.083Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x007FdA772e56cF406Dc6a907E96728864B3F6663': 1}, 'asks_updated': '2024-03-25T09:40:58.874203831Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.0078125, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece5', 'name': 'togethercomputer/RedPajama-INCITE-Base-3B-v1', 'display_name': 'RedPajama-INCITE (3B)', 'display_type': 'language', 'description': 'Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).', 'descriptionLink': 'https://www.together.xyz/blog/redpajama-models-v1', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '2775864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.751Z', 'update_at': '2023-06-23T20:22:43.751Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xEEe584b521fe7CC593aeDc2E5d2A510292D3698A': 1}, 'asks_updated': '2024-03-25T17:08:39.674774188Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.0078125, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece7', 'name': 'togethercomputer/RedPajama-INCITE-Chat-3B-v1', 'display_name': 'RedPajama-INCITE Chat (3B)', 'display_type': 'chat', 'description': 'Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-3B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '2775864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'add_generation_prompt': True, 'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.839Z', 'update_at': '2023-06-23T20:22:43.839Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x39a47C489b801ceBD66423D50F8c92D7b09eddcC': 1}, 'asks_updated': '2024-03-25T12:39:02.660765969Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.0078125, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece6', 'name': 'togethercomputer/RedPajama-INCITE-Instruct-3B-v1', 'display_name': 'RedPajama-INCITE Instruct (3B)', 'display_type': 'language', 'description': 'Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-3B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '2775864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.796Z', 'update_at': '2023-06-23T20:22:43.796Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0eFB61661ae0a1eBCDd4129D6BE1938225cB35a9': 1}, 'asks_updated': '2024-03-25T13:13:52.320518762Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.0078125, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65735df36923087ddd5a6607', 'name': 'togethercomputer/StripedHyena-Hessian-7B', 'display_name': 'StripedHyena Hessian (7B)', 'display_type': 'language', 'description': 'A hybrid architecture composed of multi-head, grouped-query attention and gated convolutions arranged in Hyena blocks, different from traditional decoder-only Transformers', 'license': 'Apache-2', 'creator_organization': 'Together', 'hardware_label': 'H100', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'release_date': '2023-11-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-12-08T18:18:27.005Z', 'update_at': '2023-12-08T19:03:32.567Z', 'instances': [{'avzone': 'ap-northeast-1a', 'cluster': 'optimisticotter'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x4f668aC29a75F8fD86d653D1754eCd0763c5d667': 1}, 'asks_updated': '2024-03-25T18:18:16.817994003Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'ap-northeast-1a', 'cluster': 'optimisticotter', 'capacity': 0.03571428571428571, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65735d536923087ddd5a6606', 'name': 'togethercomputer/StripedHyena-Nous-7B', 'display_name': 'StripedHyena Nous (7B)', 'display_type': 'chat', 'description': 'A hybrid architecture composed of multi-head, grouped-query attention and gated convolutions arranged in Hyena blocks, different from traditional decoder-only Transformers', 'license': 'Apache-2', 'creator_organization': 'Together', 'hardware_label': 'H100', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'release_date': '2023-11-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'stop': ['###', '</s>'], 'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ bos_token + '### Instruction:\\\\n' + message['content'] + '\\\\n\\\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\\\n' + message['content'] + '\\\\n\\\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\\\n'  + message['content'] + '\\\\n' }}{% endif %}{% if loop.last %}{{ '### Response:\\\\n' }}{% endif %}{% endfor %}\", 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-12-08T18:15:47.433Z', 'update_at': '2023-12-08T19:03:11.497Z', 'instances': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xDf09DC5Df2B0116b09cB52E358e1bAbdE797c383': 1}, 'asks_updated': '2024-03-25T19:46:55.415230459Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-5a', 'cluster': 'wrigleycub', 'capacity': 0.05263157894736842, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace317227f790586239ce2', 'name': 'togethercomputer/alpaca-7b', 'display_name': 'Alpaca (7B)', 'display_type': 'chat', 'description': 'Fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. ', 'license': 'cc-by-nc-4.0', 'link': 'https://huggingface.co/tatsu-lab/alpaca-7b-wdiff', 'creator_organization': 'Stanford', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'stop': ['</s>', '###'], 'add_generation_prompt': True, 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:05:27.713Z', 'update_at': '2023-07-11T05:05:27.713Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x959Ab12a6b941A3af32D2BFAB15357B0d5a09b17': 1}, 'asks_updated': '2024-03-25T12:53:15.37589974Z', 'gpus': {'': 0}, 'qps': 0.6, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 132.93333333333334, 'throughput_out': 33.06666666666667, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.054285714285714305, 'qps': 0.6, 'throughput_in': 132.93333333333334, 'throughput_out': 33.06666666666667, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65df8df823e6726c2d053851', 'name': 'togethercomputer/evo-1-131k-base', 'display_name': 'Evo-1 Base (131K)', 'display_type': 'language', 'description': 'Evo is a biological foundation model capable of long-context modeling and design. Evo uses the StripedHyena architecture to enable modeling of sequences at a single-nucleotide, byte-level resolution with near-linear scaling of compute and memory relative to context length. Evo has 7 billion parameters and is trained on OpenGenome, a prokaryotic whole-genome dataset containing ~300 billion tokens.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/evo-1-131k-base', 'creator_organization': 'Together', 'pricing_tier': 'Featured', 'num_parameters': 6450000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 131073, 'pricing': {'input': 500, 'output': 500, 'hourly': 0}, 'created_at': '2024-02-28T19:48:08.106Z', 'update_at': '2024-02-28T19:48:08.106Z', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}], 'isPrivate': False, 'access_control': [], 'isDedicatedInstance': False, 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xc0adb2ff2096a2cbd885ac3b3b7DeaEc405929Fa': 1}, 'asks_updated': '2024-03-25T12:40:11.723667749Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6553b8da6664bf7229b2dbfb', 'name': 'togethercomputer/m2-bert-80M-2k-retrieval', 'display_name': 'M2-BERT-Retrieval-2K', 'display_type': 'embedding', 'description': 'M2-BERT from the Monarch Mixer paper fine-tuned for retrieval', 'license': 'Apache-2', 'creator_organization': 'Together', 'hardware_label': 'L40', 'pricing_tier': 'Featured', 'num_parameters': 80000000, 'release_date': '2023-11-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'pricing': {'hourly': 0, 'input': 2, 'output': 2, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-14T18:13:46.901Z', 'update_at': '2024-02-21T20:06:27.968Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x49c8561e8042ef95A4b011A0AB216d6171aAb80a': 1, '0xD797d4629f4ec41203c03e9F417A1b26C165429c': 1}, 'asks_updated': '2024-03-26T02:20:52.802332941Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6585058be7e2e898e81b5401', 'name': 'togethercomputer/m2-bert-80M-32k-retrieval', 'display_name': 'M2-BERT-Retrieval-32k', 'display_type': 'embedding', 'description': 'The 80M checkpoint for M2-BERT-base from the paper Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture with sequence length 8192, and it has been fine-tuned for retrieval.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/m2-bert-80M-32k-retrieval', 'creator_organization': 'Together', 'hardware_label': 'L40', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 80000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 32768, 'pricing': {'hourly': 0, 'input': 2, 'output': 2, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-04T17:57:24.532Z', 'update_at': '2023-11-04T17:57:24.532Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xc6B6cfB1A480437a012553De16eD296a73a8fB68': 1, '0xf72e975D2E4604CD828420C2F3F27EE7B1685D6B': 1}, 'asks_updated': '2024-03-26T00:52:15.576835748Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65468604c5ce2e5fa70d6722', 'name': 'togethercomputer/m2-bert-80M-8k-retrieval', 'display_name': 'M2-BERT-Retrieval-8k', 'display_type': 'embedding', 'description': 'The 80M checkpoint for M2-BERT-base from the paper Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture with sequence length 8192, and it has been fine-tuned for retrieval.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/m2-bert-80M-8k-retrieval', 'creator_organization': 'Together', 'hardware_label': 'L40', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 80000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'pricing': {'hourly': 0, 'input': 2, 'output': 2, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-04T17:57:24.532Z', 'update_at': '2023-11-04T17:57:24.532Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x3d324467D9c6F36d90247D092f4CF7c3409E4EC7': 1, '0xA719bF2Fb3860AfcA169Afc4B034EE02608Af21D': 1}, 'asks_updated': '2024-03-26T00:39:29.398307759Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '657f7552a9c4049b6a42e4c6', 'name': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'display_name': 'Upstage SOLAR Instruct v1 (11B)', 'display_type': 'chat', 'description': 'Built on the Llama2 architecture, SOLAR-10.7B incorporates the innovative Upstage Depth Up-Scaling', 'license': 'cc-by-nc-4.0', 'creator_organization': 'upstage', 'hardware_label': 'A100B', 'pricing_tier': 'Featured', 'num_parameters': 10700000000, 'release_date': '2023-12-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['###', '</s>'], 'prompt_format': '<s> ### User:\\n{prompt}\\n### Assistant:\\n', 'add_generation_prompt': True, 'chat_template': \"{% for message in messages %}{% if message['role'] == 'system' %}{% if message['content']%}{{'### System:\\n' + message['content']+'\\n\\n'}}{% endif %}{% elif message['role'] == 'user' %}{{'### User:\\n' + message['content']+'\\n\\n'}}{% elif message['role'] == 'assistant' %}{{'### Assistant:\\n'  + message['content']}}{% endif %}{% if loop.last and add_generation_prompt %}{{ '### Assistant:\\n' }}{% endif %}{% endfor %}\"}, 'pricing': {'input': 75, 'output': 75}, 'created_at': '2023-12-17T22:25:22.252Z', 'update_at': '2023-12-17T22:32:58.075Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x6e7b83610040F22561593472a4A239022A6fc7CE': 1}, 'asks_updated': '2024-03-26T01:00:53.898701119Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.023255813953488372, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace3af227f790586239ce6', 'name': 'wavymulder/Analog-Diffusion', 'display_name': 'Analog Diffusion', 'display_type': 'image', 'description': 'Dreambooth model trained on a diverse set of analog photographs to provide an analog film effect. ', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/wavymulder/Analog-Diffusion', 'creator_organization': 'Wavymulder', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 0, 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'created_at': '2023-07-11T05:07:59.364Z', 'update_at': '2023-07-11T05:07:59.364Z', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xC830b3583bcA51887185318c0184fbdB622A55f5': 1}, 'asks_updated': '2024-03-26T06:49:24.661871387Z', 'gpus': {'NVIDIA A40': 1}, 'options': {'input=text,image': 1}, 'qps': 0.014255286, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.25410485}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '656a79054d805f78df5fd530', 'name': 'zero-one-ai/Yi-34B-Chat', 'display_name': '01-ai Yi Chat (34B)', 'display_type': 'chat', 'description': 'The Yi series models are large language models trained from scratch by developers at 01.AI', 'license': 'yi-license', 'creator_organization': '01.AI', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 34000000000, 'release_date': '2023-11-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'add_generation_prompt': True, 'stop': ['<|im_start|>', '<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'chat_template_name': 'default'}, 'pricing': {'input': 200, 'output': 200, 'base': 0}, 'created_at': '2023-12-02T00:23:33.685Z', 'update_at': '2023-12-02T00:26:55.827Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x450aDd660C1B1fdB2A7f6bDAE850C4850594FbCD': 1, '0x454Eef2b7f085F0134db5c728ac382aD0c4C9511': 1}, 'asks_updated': '2024-03-26T03:00:14.608536005Z', 'gpus': {'': 0}, 'qps': 0.26666666666666666, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 57.13333333333333, 'throughput_out': 84.4, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.04918032786885247, 'qps': 0.26666666666666666, 'throughput_in': 57.13333333333333, 'throughput_out': 84.4, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '656fa3548d9fd20968de9ba7', 'name': 'zero-one-ai/Yi-34B', 'display_name': '01-ai Yi Base (34B)', 'display_type': 'language', 'description': 'The Yi series models are large language models trained from scratch by developers at 01.AI', 'license': 'yi-license', 'creator_organization': '01.AI', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 34000000000, 'release_date': '2023-11-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'pricing': {'input': 200, 'output': 200}, 'created_at': '2023-12-05T22:25:24.982Z', 'update_at': '2023-12-05T22:51:15.306Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x964972F1A61F8BAdbD6163b9888D284CC2E054E9': 1, '0x9B35c58ef3E3425dEa8CBE5f39b8050e40193F68': 1}, 'asks_updated': '2024-03-25T17:10:09.473554229Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.01639344262295082, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6570718281b9e1cf0455ec53', 'name': 'zero-one-ai/Yi-6B', 'display_name': '01-ai Yi Base (6B)', 'display_type': 'language', 'description': 'The Yi series models are large language models trained from scratch by developers at 01.AI', 'license': 'yi-license', 'creator_organization': '01.AI', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 6000000000, 'release_date': '2023-11-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-12-06T13:05:06.567Z', 'update_at': '2023-12-06T13:07:50.190Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x45716B6ea86D12C2ba6B1a12cbb8BDBb1fA5f136': 1, '0xf2337a3BA04f483bCb3DbF43584a398e83E20368': 1}, 'asks_updated': '2024-03-26T05:28:08.8450365Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.0078125, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65df8d9623e6726c2d053850', 'name': 'togethercomputer/evo-1-8k-base', 'display_name': 'Evo-1 Base (8K)', 'display_type': 'language', 'description': 'Evo is a biological foundation model capable of long-context modeling and design. Evo uses the StripedHyena architecture to enable modeling of sequences at a single-nucleotide, byte-level resolution with near-linear scaling of compute and memory relative to context length. Evo has 7 billion parameters and is trained on OpenGenome, a prokaryotic whole-genome dataset containing ~300 billion tokens.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/evo-1-8k-base', 'creator_organization': 'Together', 'pricing_tier': 'Featured', 'num_parameters': 6450000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'pricing': {'input': 500, 'output': 500, 'hourly': 0}, 'created_at': '2024-02-28T19:46:30.585Z', 'update_at': '2024-02-28T19:46:30.585Z', 'instances': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull'}], 'isPrivate': False, 'access_control': [], 'isDedicatedInstance': False, 'access': '', 'hardware_label': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0, 'stats': [{'avzone': 'us-central-5b', 'cluster': 'blusterybull', 'capacity': 0, 'qps': 0, 'throughput_in': 0, 'throughput_out': 0, 'error_rate': 0, 'retry_rate': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecbe', 'name': 'EleutherAI/pythia-1b-v0', 'display_name': 'Pythia (1B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 1000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.925Z', 'update_at': '2023-06-23T20:22:41.925Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '649e1ccca073332e47742415', 'name': 'replit/replit-code-v1-3b', 'display_name': 'Replit-Code-v1 (3B)', 'display_type': 'code', 'description': 'replit-code-v1-3b is a 2.7B Causal Language Model focused on Code Completion. The model has been trained on a subset of the Stack Dedup v1.2 dataset.', 'license': '', 'link': '', 'creator_organization': 'Replit', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'limited', 'num_parameters': 3000000000, 'release_date': '2023-04-26T00:00:00.000Z', 'show_in_playground': 'true', 'isFeaturedModel': False, 'context_length': 2048, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-30T00:07:40.594Z', 'update_at': '2023-07-07T20:09:09.965Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecee', 'name': 'togethercomputer/Pythia-Chat-Base-7B-v0.16', 'display_name': 'Pythia-Chat-Base (7B)', 'display_type': 'chat', 'description': 'Chat model based on EleutherAIs Pythia-7B model, and is fine-tuned with data focusing on dialog-style interactions.', 'license': '', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.251Z', 'update_at': '2023-06-23T20:22:44.251Z', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceada227f790586239d11', 'name': 'mosaicml/mpt-7b', 'display_name': 'MPT (7B)', 'display_type': 'language', 'description': 'Decoder-style transformer pretrained from scratch on 1T tokens of English text and code.', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:38:34.852Z', 'update_at': '2023-07-15T03:06:20.780Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceb0e227f790586239d12', 'name': 'togethercomputer/mpt-30b-chat', 'display_name': 'MPT-Chat (30B)', 'display_type': 'chat', 'description': 'Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 30000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant', 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:39:26.078Z', 'update_at': '2023-07-11T05:39:26.078Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace6df227f790586239cfc', 'name': 'google/flan-t5-xl', 'display_name': 'Flan T5 XL (3B)', 'display_type': 'language', 'description': 'T5 fine-tuned on more than 1000 additional tasks covering also more languages, making it better than T5 at majority of tasks. ', 'license': '', 'link': '', 'creator_organization': 'Google', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 512, 'config': {'chat_template_name': 'default'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.261Z', 'update_at': '2023-06-23T20:22:42.261Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acebe0227f790586239d17', 'name': 'NumbersStation/nsql-6B', 'display_name': 'NSQL (6B)', 'display_type': 'language', 'description': 'Foundation model designed specifically for SQL generation tasks. Pre-trained for 3 epochs and fine-tuned for 10 epochs.', 'license': '', 'creator_organization': 'Numbers Station', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 6000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:42:56.540Z', 'update_at': '2023-07-11T05:42:56.540Z', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace9ca227f790586239d09', 'name': 'togethercomputer/Koala-7B', 'display_name': 'Koala (7B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} GPT:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'GPT: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ 'GPT:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:34:02.521Z', 'update_at': '2023-07-11T05:34:02.521Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc0', 'name': 'EleutherAI/pythia-6.9b', 'display_name': 'Pythia (6.9B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'num_parameters': 6900000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.044Z', 'update_at': '2023-06-23T20:22:42.044Z', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecb8', 'name': 'databricks/dolly-v2-12b', 'display_name': 'Dolly v2 (12B)', 'display_type': 'chat', 'description': 'An instruction-following LLM based on pythia-12b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.', 'license': '', 'link': '', 'creator_organization': 'Databricks', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 12000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['### End'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.607Z', 'update_at': '2023-06-23T20:22:41.607Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecb6', 'name': 'databricks/dolly-v2-3b', 'display_name': 'Dolly v2 (3B)', 'display_type': 'chat', 'description': 'An instruction-following LLM based on pythia-3b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.', 'license': '', 'link': '', 'creator_organization': 'Databricks', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['### End'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.524Z', 'update_at': '2023-06-23T20:22:41.524Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc2', 'name': 'EleutherAI/gpt-neox-20b', 'display_name': 'GPT-NeoX (20B)', 'display_type': 'language', 'description': 'Autoregressive language model trained on the Pile. Its architecture intentionally resembles that of GPT-3, and is almost identical to that of GPT-J 6B.', 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 20000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.132Z', 'update_at': '2023-06-23T20:22:42.132Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecbf', 'name': 'EleutherAI/pythia-2.8b-v0', 'display_name': 'Pythia (2.8B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'num_parameters': 2800000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.975Z', 'update_at': '2023-06-23T20:22:41.975Z', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acebb2227f790586239d16', 'name': 'NousResearch/Nous-Hermes-13b', 'display_name': 'Nous Hermes (13B)', 'display_type': 'language', 'description': 'LLaMA 13B fine-tuned on over 300,000 instructions. Designed for long responses, low hallucination rate, and absence of censorship mechanisms.', 'license': '', 'link': '', 'creator_organization': 'Nous Research', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:42:10.444Z', 'update_at': '2023-07-11T05:42:10.444Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace8d1227f790586239d03', 'name': 'togethercomputer/guanaco-65b', 'display_name': 'Guanaco (65B) ', 'display_type': 'chat', 'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.', 'license': '', 'link': '', 'creator_organization': 'Tim Dettmers', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Supported', 'access': 'open', 'num_parameters': 65000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['###'], 'prompt_format': '### Human: {prompt} ### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-11T05:29:53.740Z', 'update_at': '2023-07-11T05:29:53.740Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e5', 'name': 'togethercomputer/llama-2-7b', 'display_name': 'LLaMA-2 (7B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': '', 'link': '', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'renamed': 'meta-llama/Llama-2-7b-hf', 'hardware_label': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acf031227f790586239d44', 'name': 'lmsys/fastchat-t5-3b-v1.0', 'display_name': 'Vicuna-FastChat-T5 (3B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning Flan-t5-xl on user-shared conversations collected from ShareGPT.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 512, 'config': {'stop': ['###', '</s>'], 'prompt_format': '### Human: {prompt}\\n### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + '\\n' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-07-11T06:01:21.713Z', 'update_at': '2023-07-11T06:01:21.713Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea6e227f790586239d0e', 'name': 'huggyllama/llama-7b', 'display_name': 'LLaMA (7B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:36:46.255Z', 'update_at': '2023-07-11T05:36:46.255Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc9', 'name': 'OpenAssistant/stablelm-7b-sft-v7-epoch-3', 'display_name': 'Open-Assistant StableLM SFT-7 (7B)', 'display_type': 'chat', 'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ', 'license': '', 'link': '', 'creator_organization': 'LAION', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.425Z', 'update_at': '2023-06-23T20:22:42.425Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc1', 'name': 'EleutherAI/pythia-12b-v0', 'display_name': 'Pythia (12B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 12000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.091Z', 'update_at': '2023-06-23T20:22:42.091Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceb28227f790586239d13', 'name': 'togethercomputer/mpt-7b-chat', 'display_name': 'MPT-Chat (7B)', 'display_type': 'chat', 'description': 'Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant', 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:39:52.024Z', 'update_at': '2023-07-11T05:39:52.024Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecbc', 'name': 'EleutherAI/gpt-j-6b', 'display_name': 'GPT-J (6B)', 'display_type': 'language', 'description': \"Transformer model trained using Ben Wang's Mesh Transformer JAX. \", 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 6000000000, 'release_date': '2021-06-04T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.831Z', 'update_at': '2023-06-23T20:22:41.831Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc8', 'name': 'OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5', 'display_name': 'Open-Assistant Pythia SFT-4 (12B)', 'display_type': 'chat', 'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ', 'license': '', 'link': '', 'creator_organization': 'LAION', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 12000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.383Z', 'update_at': '2023-06-23T20:22:42.383Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acf013227f790586239d43', 'name': 'lmsys/vicuna-7b-v1.3', 'display_name': 'Vicuna v1.3 (7B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T06:00:51.553Z', 'update_at': '2023-07-11T06:00:51.553Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5cc', 'name': 'Phind/Phind-CodeLlama-34B-Python-v1', 'display_name': 'Phind Code LLaMA Python v1 (34B)', 'display_type': 'code', 'description': 'This model is fine-tuned from CodeLlama-34B-Python and achieves 69.5% pass@1 on HumanEval.', 'license': '', 'creator_organization': 'Phind', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 33743970304, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'stop': ['</s>', '###'], 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65ac4e5e75846d9d3ae5b836', 'name': 'NumbersStation/nsql-llama-2-7B', 'display_name': 'NSQL LLaMA-2 (7B)', 'display_type': 'code', 'description': 'NSQL is a family of autoregressive open-source large foundation models (FMs) designed specifically for SQL generation tasks', 'link': '', 'creator_organization': 'Numbers Station', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 7000000000, 'release_date': '2024-01-20T22:51:10.492Z', 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'pricing': {'hourly': 0, 'input': 50, 'output': 50, 'finetune': 0, 'base': 0}, 'created_at': '2024-01-20T22:51:10.492Z', 'update_at': '2024-01-20T22:59:48.333Z', 'access': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf8', 'name': 'NousResearch/Nous-Hermes-Llama2-70b', 'display_name': 'Nous Hermes LLaMA-2 (70B)', 'display_type': 'chat', 'description': 'Nous-Hermes-Llama2-70b is a state-of-the-art language model fine-tuned on over 300,000 instructions.', 'license': '', 'link': '', 'creator_organization': 'NousResearch', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 70000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['###', '</s>'], 'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:\\n', 'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.404Z', 'update_at': '2023-10-24T17:43:39.278Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f67555bc372ce719b97f03', 'name': 'WizardLM/WizardLM-70B-V1.0', 'display_name': 'WizardLM v1.0 (70B)', 'display_type': 'language', 'description': 'This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities.', 'license': '', 'creator_organization': 'WizardLM', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'supported', 'num_parameters': 70000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} ASSISTANT:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'ASSISTANT:' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-09-05T00:24:53.327Z', 'update_at': '2023-09-05T00:24:53.327Z', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea57227f790586239d0d', 'name': 'huggyllama/llama-65b', 'display_name': 'LLaMA (65B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 65000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-11T05:36:23.656Z', 'update_at': '2023-07-11T05:36:23.656Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5ce', 'name': 'lmsys/vicuna-13b-v1.5-16k', 'display_name': 'Vicuna v1.5 16K (13B)', 'display_type': 'chat', 'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.', 'license': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13015864320, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'stop': ['</s>'], 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece4', 'name': 'togethercomputer/GPT-NeoXT-Chat-Base-20B', 'display_name': 'GPT-NeoXT-Chat-Base (20B)', 'display_type': 'chat', 'description': 'Chat model fine-tuned from EleutherAIs GPT-NeoX with over 40 million instructions on carbon reduced compute.', 'license': '', 'link': '', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 20000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'max_tokens': 995, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.702Z', 'update_at': '2023-06-23T20:22:43.702Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '657bed666aca120ac2af2fb7', 'name': 'HuggingFaceH4/zephyr-7b-beta', 'display_name': 'Zephyr-7B-', 'display_type': 'chat', 'description': 'A fine-tuned version of Mistral-7B to act as a helpful assistant.', 'license': '', 'link': '', 'creator_organization': 'HuggingFace', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 7241732096, 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 32768, 'config': {'stop': ['[INST]', '</s>'], 'prompt_format': '<s>[INST] {prompt} [INST]'}, 'created_at': '2023-12-15T06:08:38.925Z', 'update_at': '2023-12-15T06:08:38.925Z', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6de96e620478cfa144262', 'name': 'codellama/CodeLlama-34b-hf', 'display_name': 'Code Llama (34B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 194, 'output': 194, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78e89589782acafe1781d', 'name': 'togethercomputer/CodeLlama-7b-Instruct', 'display_name': 'Code Llama Instruct (7B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'renamed': 'codellama/CodeLlama-7b-Instruct-hf', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f0de22caa9e2eb543b373b', 'name': 'togethercomputer/guanaco-13b', 'display_name': 'Guanaco (13B) ', 'display_type': 'chat', 'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.', 'license': '', 'link': '', 'creator_organization': 'Tim Dettmers', 'hardware_label': 'A40 48GB', 'pricing_tier': 'Supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['###'], 'prompt_format': '### Human: {prompt} ### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:29:07.717Z', 'update_at': '2023-07-11T05:29:07.717Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e7934a589782acafe17822', 'name': 'togethercomputer/CodeLlama-34b-Python', 'display_name': 'Code Llama Python (34B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 194, 'output': 194, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'renamed': 'codellama/CodeLlama-34b-Python-hf', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceb6f227f790586239d15', 'name': 'mosaicml/mpt-7b-instruct', 'display_name': 'MPT-Instruct (7B)', 'display_type': 'language', 'description': 'Designed for short-form instruction following, finetuned on Dolly and Anthropic HH-RLHF and other datasets', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:41:03.757Z', 'update_at': '2023-07-11T05:41:03.757Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07ea', 'name': 'togethercomputer/llama-2-70b-chat', 'display_name': 'LLaMA-2 Chat (70B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '68976648192', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'autopilot_pool': 'cr-a100-80-2x', 'renamed': 'meta-llama/Llama-2-70b-chat-hf', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e7934a589782acafe17823', 'name': 'togethercomputer/CodeLlama-34b-Instruct', 'display_name': 'Code Llama Instruct (34B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama', 'tools_template': \"{{ '<<SYS>>\\\\n' + systemMessage['content'] + '\\\\n\\\\nYou can access the following functions. Use them if required -\\\\n' + tools + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] }}\"}, 'pricing': {'input': 194, 'output': 194, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'renamed': 'codellama/CodeLlama-34b-Instruct-hf', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e7934a589782acafe17821', 'name': 'togethercomputer/CodeLlama-34b', 'display_name': 'Code Llama (34B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 194, 'output': 194, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'renamed': 'codellama/CodeLlama-34b-hf', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78eba589782acafe1781f', 'name': 'togethercomputer/CodeLlama-13b-Python', 'display_name': 'Code Llama Python (13B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 55, 'output': 55, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-12-20T22:52:59.177Z', 'renamed': 'codellama/CodeLlama-13b-Python-hf', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecf1', 'name': 'Salesforce/codegen2-16B', 'display_name': 'CodeGen2 (16B)', 'display_type': 'code', 'description': 'An autoregressive language models for program synthesis.', 'license': '', 'link': '', 'creator_organization': 'Salesforce', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 16000000000, 'release_date': '2022-03-25T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['\\n\\n'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.453Z', 'update_at': '2023-06-23T20:22:44.453Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace476227f790586239cef', 'name': 'Salesforce/codegen2-7B', 'display_name': 'CodeGen2 (7B)', 'display_type': 'code', 'description': 'An autoregressive language models for program synthesis.', 'license': '', 'link': '', 'creator_organization': 'Salesforce', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'release_date': '2022-03-25T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['\\n\\n'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:11:18.328Z', 'update_at': '2023-07-11T05:11:18.328Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc5', 'name': 'google/flan-t5-xxl', 'display_name': 'Flan T5 XXL (11B)', 'display_type': 'language', 'description': 'Flan T5 XXL (11B parameters) is T5 fine-tuned on 1.8K tasks ([paper](https://arxiv.org/pdf/2210.11416.pdf)).', 'creator_organization': 'Google', 'hardware_label': 'A40 48GB', 'access': 'open', 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 512, 'config': {'chat_template_name': 'default'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.261Z', 'update_at': '2023-09-01T14:35:00.161Z', 'license': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e9', 'name': 'togethercomputer/llama-2-70b', 'display_name': 'LLaMA-2 (70B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '68976648192', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'autopilot_pool': 'cr-a100-80-2x', 'renamed': 'meta-llama/Llama-2-70b-hf', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6de95e620478cfa14425f', 'name': 'codellama/CodeLlama-7b-hf', 'display_name': 'Code Llama (7B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65a6de95e620478cfa14425c', 'name': 'codellama/CodeLlama-13b-hf', 'display_name': 'Code Llama (13B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 55, 'output': 55, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-12-21T01:12:38.916Z', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78eba589782acafe17820', 'name': 'togethercomputer/CodeLlama-13b-Instruct', 'display_name': 'Code Llama Instruct (13B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama'}, 'pricing': {'input': 55, 'output': 55, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-12-04T05:01:42.539Z', 'renamed': 'codellama/CodeLlama-13b-Instruct-hf', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e8', 'name': 'togethercomputer/llama-2-13b-chat', 'display_name': 'LLaMA-2 Chat (13B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': '', 'link': '', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '13015864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 55, 'output': 55, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-12-04T05:00:54.436Z', 'renamed': 'meta-llama/Llama-2-13b-chat-hf', 'hardware_label': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e7', 'name': 'togethercomputer/llama-2-13b', 'display_name': 'LLaMA-2 (13B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': '', 'link': '', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '13015864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 55, 'output': 55, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-12-04T05:07:52.318Z', 'renamed': 'meta-llama/Llama-2-13b-hf', 'hardware_label': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acefe5227f790586239d41', 'name': 'lmsys/vicuna-13b-v1.3', 'display_name': 'Vicuna v1.3 (13B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T06:00:05.166Z', 'update_at': '2023-07-15T03:08:44.173Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea0b227f790586239d0b', 'name': 'huggyllama/llama-13b', 'display_name': 'LLaMA (13B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:35:07.955Z', 'update_at': '2023-07-11T05:35:07.955Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acefbe227f790586239d40', 'name': 'HuggingFaceH4/starchat-alpha', 'display_name': 'StarCoderChat Alpha (16B)', 'display_type': 'chat', 'description': 'Fine-tuned from StarCoder to act as a helpful coding assistant. As an alpha release is only intended for educational or research purpopses.', 'license': '', 'link': '', 'creator_organization': 'HuggingFaceH4', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 16000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 8192, 'config': {'stop': ['<|endoftext|>', '<|end|>'], 'prompt_format': '<|system|>\\n<|end|>\\n<|user|>\\n{prompt}<|end|>\\n<|assistant|>', 'chat_template_name': 'default'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:59:26.298Z', 'update_at': '2023-07-11T05:59:26.298Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea35227f790586239d0c', 'name': 'huggyllama/llama-30b', 'display_name': 'LLaMA (30B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'access': 'open', 'num_parameters': 33000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:35:49.870Z', 'update_at': '2023-07-11T05:35:49.870Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecf4', 'name': 'stabilityai/stablelm-base-alpha-3b', 'display_name': 'StableLM-Base-Alpha (3B)', 'display_type': 'language', 'description': 'Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.', 'license': '', 'link': '', 'creator_organization': 'Stability AI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.907Z', 'update_at': '2023-06-23T20:22:44.907Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1512907e072b8aecf5', 'name': 'stabilityai/stablelm-base-alpha-7b', 'display_name': 'StableLM-Base-Alpha (7B)', 'display_type': 'language', 'description': 'Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.', 'license': '', 'link': '', 'creator_organization': 'Stability AI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:45.249Z', 'update_at': '2023-06-23T20:22:45.249Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78e89589782acafe1781c', 'name': 'togethercomputer/CodeLlama-7b-Python', 'display_name': 'Code Llama Python (7B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 16384, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'renamed': 'codellama/CodeLlama-7b-Python-hf', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f67987bc372ce719b97f07', 'name': 'defog/sqlcoder', 'display_name': 'Sqlcoder (15B)', 'display_type': 'language', 'description': \"Defog's SQLCoder is a state-of-the-art LLM for converting natural language questions to SQL queries, fine-tuned from Bigcode's Starcoder 15B model.\", 'license': '', 'creator_organization': 'Defog', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 15000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 8192, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '### Instructions:\\n\\n{prompt}\\n\\n### Response:\\n'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-05T00:42:47.496Z', 'update_at': '2023-09-05T00:42:47.496Z', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acef6e227f790586239d3f', 'name': 'bigcode/starcoder', 'display_name': 'StarCoder (16B)', 'display_type': 'code', 'description': 'Trained on 80+ coding languages, uses Multi Query Attention, an 8K context window, and was trained using the Fill-in-the-Middle objective on 1T tokens.', 'license': '', 'link': '', 'creator_organization': 'BigCode', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'num_parameters': 16000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 8192, 'config': {'stop': ['<|endoftext|>', '<|end|>']}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:58:06.486Z', 'update_at': '2023-07-11T05:58:06.486Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecb7', 'name': 'databricks/dolly-v2-7b', 'display_name': 'Dolly v2 (7B)', 'display_type': 'chat', 'description': 'An instruction-following LLM based on pythia-7b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.', 'license': '', 'link': '', 'creator_organization': 'Databricks', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['### End'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.565Z', 'update_at': '2023-06-23T20:22:41.565Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace8a3227f790586239d02', 'name': 'togethercomputer/guanaco-33b', 'display_name': 'Guanaco (33B) ', 'display_type': 'chat', 'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.', 'license': '', 'link': '', 'creator_organization': 'Tim Dettmers', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Supported', 'access': 'open', 'num_parameters': 33000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['###'], 'prompt_format': '### Human: {prompt} ### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:29:07.717Z', 'update_at': '2023-07-11T05:29:07.717Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace9b1227f790586239d07', 'name': 'togethercomputer/Koala-13B', 'display_name': 'Koala (13B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} GPT:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'GPT: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ 'GPT:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:33:37.737Z', 'update_at': '2023-07-11T05:33:37.737Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece2', 'name': 'togethercomputer/GPT-JT-6B-v1', 'display_name': 'GPT-JT (6B)', 'display_type': 'language', 'description': 'Fork of GPT-J instruction tuned to excel at few-shot prompts (blog post).', 'descriptionLink': 'https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai', 'license': '', 'link': '', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 6700000000, 'release_date': '2022-11-29T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.617Z', 'update_at': '2023-06-23T20:22:43.617Z'}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e6', 'name': 'togethercomputer/llama-2-7b-chat', 'display_name': 'LLaMA-2 Chat (7B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': '', 'link': '', 'creator_organization': 'Meta', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'renamed': 'meta-llama/Llama-2-7b-chat-hf', 'hardware_label': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace8ed227f790586239d04', 'name': 'togethercomputer/guanaco-7b', 'display_name': 'Guanaco (7B) ', 'display_type': 'chat', 'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks. ', 'license': '', 'link': '', 'creator_organization': 'Tim Dettmers', 'hardware_label': 'A40 48GB', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['###'], 'prompt_format': '### Human: {prompt} ### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:30:21.531Z', 'update_at': '2023-07-11T05:30:21.531Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf7', 'name': 'EleutherAI/llemma_7b', 'display_name': 'Llemma (7B)', 'display_type': 'language', 'description': 'Llemma 7B is a language model for mathematics. It was initialized with Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens.', 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 6738546688, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.403Z', 'update_at': '2023-10-24T17:42:38.630Z', 'descriptionLink': ''}]\n"
     ]
    }
   ],
   "source": [
    "models= together.Models.list()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_model_together(prompt):\n",
    "    response=together.Complete.create(\n",
    "        prompt,\n",
    "        model=\"togethercomputer/llama-2-70b-chat\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0\n",
    "    )\n",
    "    text= response['output']['choices'][0]['text'].replace('\\n', ' ').strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the purpose of our existence? These are questions that have puzzled philosophers and theologians for centuries. In this essay, I will examine the meaning of life and the purpose of our existence from a philosophical perspective. I will discuss the views of several philosophers, including Plato, Aristotle, and Jean-Paul Sartre, and examine how their ideas can help us understand the meaning of life. Plato believed that the meaning of life is to seek knowledge and understanding. According to Plato, the world we experience through our senses is only an imitation of the true world, which is a world of abstract Forms or Ideas. The Forms are eternal, unchanging, and perfect, while the world we experience is imperfect and constantly changing. Plato believed that the purpose of our existence is to seek knowledge of the Forms, which will allow us to understand the true nature of reality. In his dialogue, The Republic, Plato wrote, The unexamined life is not worth living. This statement highlights the importance of self-reflection and the pursuit of knowledge in understanding the meaning of life. Aristotle, a student of Plato, had a different view of the meaning of life. Aristotle believed that the purpose of our existence is to achieve happiness and fulfillment. According to Aristotle, happiness is not a fleeting emotion, but rather a state of being that results from living a virtuous life. Aristotle believed that humans have a unique potential for rational thought and that the purpose of our existence is to develop and exercise this potential. In his Nicomachean Ethics, Aristotle wrote, Happiness is the meaning and the purpose of human life, the whole aim and end of human existence. Jean-Paul Sartre, a 20th-century philosopher, had a very different view of the meaning of life. Sartre believed that life has no inherent meaning and that it is up to each individual to create their own purpose. According to Sartre, humans are free to choose their own path in life and to create their own meaning. Sartre wrote, Man is condemned to be free; because once thrown into the world, he is forced to choose. Sartres existentialist philosophy emphasizes the individuals freedom and responsibility to create their own meaning in life. In conclusion, the meaning of life and the purpose of our existence are questions that have puzzled philosophers for centuries. Plato believed that the meaning of life is to seek knowledge and understanding, Aristotle believed that it is to achieve happiness and fulfillment, and Sartre believed that it is up to each individual to create their own purpose. These philosophers offer different perspectives on the meaning of life, but they all emphasize the importance of self-reflection and the pursuit of knowledge in understanding our existence. Ultimately, the meaning of life may be something that each individual must determine for themselves, based on their own beliefs, values, and experiences.\n"
     ]
    }
   ],
   "source": [
    "output= print(complete_model_together(\"What is the meaning of life?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
